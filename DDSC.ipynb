{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminative Sparse Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import librosa\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import SparseCoder,DictionaryLearning\n",
    "from sklearn import cluster\n",
    "# from lightning.regression import CDRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDSC():\n",
    "    def __init__(self, train_set, train_sum, alpha, \n",
    "                 epsilon, reg_lambda, steps, n, m, T, k):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            train_set: X_i matrix with dim T*m for each individual appliance \n",
    "            train_sum: X_sum aggregated matrix T*m \n",
    "            alpha: gradiant rate for the convergence step for DD (4b).\n",
    "            epsilon: gradient stepsize of the pre-training (2e) ||A_t+1 - A_t||< epsilon \n",
    "            reg_lambda: reguarization weight of penalty function\n",
    "            steps: interations to be performed for the convergence part\n",
    "            n: number of basis functions \n",
    "            m: number of features (households)\n",
    "            T: number of samples (hours)\n",
    "            k: number of applicances i (1, k)\n",
    "        \"\"\"\n",
    "        self.train_set = train_set\n",
    "        self.train_sum = train_sum\n",
    "        self.alpha = alpha \n",
    "        self.epsilon = epsilon\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.steps = steps\n",
    "        self.n = n \n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.k = k\n",
    "        \n",
    "        # ======= Instances that can be used for plotting =====\n",
    "        self.acc_nnsc = None\n",
    "        self.err_nnsc = None\n",
    "        self.acc_ddsc = None\n",
    "        self.err_ddsc = None\n",
    "        self.a_nnsc = None\n",
    "        self.b_nnsc = None\n",
    "        self.a_ddsc = None\n",
    "        self.b_ddsc = None\n",
    "\n",
    "    def _initialization(self):\n",
    "        '''\n",
    "        DDSC step 1\n",
    "        initiualize the matrices A,B with positive values\n",
    "        scale columns of B s.t b(j) = 1\n",
    "        '''\n",
    "        A = np.random.random((self.n,self.m)) # A: n*m\n",
    "        B = np.random.random((self.T,self.n)) # B: T*n\n",
    "\n",
    "        # scale columns s.t. b_i^(j) = 1\n",
    "        B /= sum(B) \n",
    "        \n",
    "        return A, B\n",
    "    \n",
    "    @staticmethod\n",
    "    def _pos_constraint(mat):\n",
    "        '''\n",
    "        nnsc step 2(b)\n",
    "        using only the positive values of matrix  \n",
    "        input: matrix n*m \n",
    "        '''     \n",
    "        indices = np.where(mat < 0.0)\n",
    "        mat[indices] = 0.0\n",
    "        return mat   \n",
    "    \n",
    "    def nnsc(self, X_dic):\n",
    "        '''\n",
    "        Method as in NNSC from nonnegative sparse coding finland.\n",
    "        from P.Hoyer\n",
    "        X_dic: dict of X_i for all appliances\n",
    "        '''\n",
    "        \n",
    "        acc_nnsc = []\n",
    "        err_nnsc = []\n",
    "        a_nnsc = []\n",
    "        b_nnsc = []\n",
    "        # used for F\n",
    "        X_train = self.train_set.values()\n",
    "        A_list = []\n",
    "        B_list = []\n",
    "        for X in X_dic:\n",
    "            # step 1 \n",
    "            A0, B0 = self._initialization() # initialization \n",
    "            Ap, Bp = A0, B0 \n",
    "            Ap1, Bp1 = Ap, Bp # record previous step Ap, Bp\n",
    "            t = 0\n",
    "            change_A = 1.0\n",
    "            while t <= self.steps and change_A >= self.epsilon:            \n",
    "                Bp = Bp - self.alpha * np.dot((np.dot(Bp, Ap) - X), Ap.T) # step 2a\n",
    "                Bp = self._pos_constraint(Bp) # step 2b \n",
    "                Bp /= sum(Bp) # step 2c \n",
    "                \n",
    "                # step 2d\n",
    "                dot_part2 = np.divide(np.dot(Bp.T,X),(np.dot(np.dot(Bp.T,Bp),Ap) + self.reg_lambda)) # element wise division \n",
    "                Ap = np.multiply(Ap,dot_part2)\n",
    "\n",
    "                change_A = np.linalg.norm(Ap - Ap1)\n",
    "                change_B = np.linalg.norm(Bp - Bp1)\n",
    "                Ap1, Bp1 = Ap, Bp\n",
    "                t += 1\n",
    "                \n",
    "                print(\"iter {t}：A change = {a:8.4f}\".format(t=t, a=change_A))\n",
    "                \n",
    "            print(\"Gone through one appliance.\\n\")\n",
    "            A_list.append(Ap)\n",
    "            B_list.append(Bp)\n",
    "\n",
    "\n",
    "        # for thesis\n",
    "        acc_iter = self.accuracy(X_train,self.train_sum,B_list,A_list)\n",
    "        err_iter = self.error(X_train,self.train_sum,B_list,A_list)\n",
    "        acc_nnsc.append(acc_iter)\n",
    "        err_nnsc.append(err_iter)\n",
    "        # append norm of matrices\n",
    "        a_nnsc.append(np.linalg.norm(sum(A_list)))\n",
    "        b_nnsc.append(np.linalg.norm(sum(B_list)))\n",
    "\n",
    "        self.acc_nnsc = acc_nnsc\n",
    "        self.err_nnsc = err_nnsc\n",
    "        self.a_nnsc = a_nnsc\n",
    "        self.b_nnsc = b_nnsc\n",
    "        return A_list,B_list\n",
    "\n",
    "    def accuracy(self,X,X_sum,B,A):\n",
    "        '''\n",
    "        Everything needs to be in lists of ndarrays\n",
    "        of the components\n",
    "        '''\n",
    "        B_cat = np.hstack(B)\n",
    "        A_cat = np.vstack(A)\n",
    "\n",
    "        A_prime = self.F(X_sum.values,B_cat,A=A_cat)\n",
    "        A_last = np.split(A_prime,self.k,axis=0)\n",
    "        X_predict = self.predict(A_last,B)\n",
    "        acc_numerator = (map(lambda i: (np.minimum( (B[i].dot(A_last[i])).sum(), \n",
    "                        (sum(list(X)[i].sum())))),\n",
    "                        range(len(B))))\n",
    "        acc_denominator = sum(X_predict).sum()\n",
    "        acc = sum(acc_numerator) / acc_denominator\n",
    "        \n",
    "        acc_numerator = (map(lambda i: (np.minimum( (B[i].dot(A_last[i])).sum() ,\n",
    "                        (sum(list(X)[i].sum())))) ,\n",
    "                        range(len(B))))\n",
    "        acc_denominator = X_sum.values.sum()\n",
    "        acc_star = sum(acc_numerator) / acc_denominator\n",
    "        return acc, acc_star\n",
    "\n",
    "    def get_accuracy_plot(self):\n",
    "        return self.acc_nnsc, self.acc_ddsc\n",
    "\n",
    "    def get_error_plot(self):\n",
    "        return self.err_nnsc, self.err_ddsc\n",
    "\n",
    "    def get_a(self):\n",
    "        return self.a_nnsc, self.a_ddsc\n",
    "\n",
    "    def get_b(self):\n",
    "        return self.b_nnsc, self.b_ddsc\n",
    "\n",
    "    def error(self,x,x_sum,B,A):\n",
    "        '''\n",
    "        Error for the whole disaggregation part within list, sum the list to get\n",
    "        the resulting disaggregation\n",
    "        Parameters : must have x_train as x\n",
    "        '''\n",
    "        B_cat = np.hstack(B)\n",
    "        A_cat = np.vstack(A)\n",
    "        \n",
    "        error = (map(lambda i: ((1.0/2.0)*np.linalg.norm( (list(x)[i] - B[i].dot(A[i]))**2)), range(len(B))))\n",
    "        error = sum(error)\n",
    "        \n",
    "        A_last_error = self.F(x_sum.values,B_cat,A_cat)\n",
    "        A_last_error_list = np.split(A_last_error,self.k,axis=0)\n",
    "        error_star = (map(lambda i: ((1.0/2.0)*np.linalg.norm((list(x)[i] - B[i].dot(A_last_error_list[i]))**2)),range(len(B))))\n",
    "        error_star = sum(error_star)\n",
    "        return error, error_star\n",
    "\n",
    "    def pre_training(self,X_dict):\n",
    "        # TODO : implement s.t. conditions and frobenius norm to the options\n",
    "        tic = time.time()\n",
    "        #the NON NEGATIVE SPARSE CODING\n",
    "        A_list,B_list = self.nnsc(X_dict)\n",
    "\n",
    "        tac = time.time()\n",
    "        t = tac - tic\n",
    "        print('time of computations for Dictionary Learning with m = {m} and T = {T} took: {t:.3f}s'.format(m=self.m,T=self.T,t=t))\n",
    "        return A_list,B_list\n",
    "        \n",
    "    \n",
    "    def F(self, X_sum, B, A):\n",
    "        '''\n",
    "        input is lists of the elements\n",
    "        output list of elements\n",
    "        '''\n",
    "        # 4a  \n",
    "        B = np.asarray(B)\n",
    "        A = np.asarray(A)\n",
    "        \n",
    "        coder = SparseCoder(dictionary=B.T,\n",
    "                            transform_alpha=self.reg_lambda, transform_algorithm='lasso_cd')    \n",
    "        # B: basis function \n",
    "        # A: activation function   \n",
    "        B_hat, A_hat = librosa.decompose.decompose(X_sum,transformer=coder) \n",
    "        A_hat = self._pos_constraint(A_hat)\n",
    "\n",
    "        return A_hat\n",
    "\n",
    "    def DD(self, X_sum, B, A):\n",
    "        '''\n",
    "        Taking the parameters as x_train_use and discriminate over the\n",
    "        entire region\n",
    "        '''\n",
    "        # step 3\n",
    "        A_star = np.vstack(A)\n",
    "        B_cat = np.hstack(B)\n",
    "        \n",
    "        # step 4 \n",
    "        change_B = 1 \n",
    "        t = 0\n",
    "        \n",
    "        acc_ddsc = []\n",
    "        err_ddsc = []\n",
    "        a_ddsc = []\n",
    "        b_ddsc = []\n",
    "        \n",
    "        X = self.train_set.values()\n",
    "        \n",
    "        while t <= self.steps and self.epsilon <= change_B:\n",
    "            B_cat_p = B_cat\n",
    "            # step 4a\n",
    "            A_hat = self.F(X_sum, B_cat, A_star)\n",
    "            # step 4b\n",
    "            B_cat = (B_cat - self.alpha * ((X_sum - B_cat.dot(A_hat)).dot(A_hat.T) - (X_sum - B_cat.dot(A_star)).dot(A_star.T)))\n",
    "            # step 4c\n",
    "            B_cat = self._pos_constraint(B_cat) # scale columns s.t. b_i^(j) = 1\n",
    "            B_cat /= sum(B_cat)\n",
    "            \n",
    "            change_B = np.linalg.norm(B_cat - B_cat_p)\n",
    "            t += 1\n",
    "            print(\"step {t}: DD change = {c:.4f}\".format(t=t, c=change_B))\n",
    "\n",
    "            # convergence check\n",
    "            A_hat_split = np.split(A_hat, self.k, axis=0)\n",
    "            B_split = np.split(B_cat,self.k,axis=1)\n",
    "            acc_iter = self.accuracy(X, self.train_sum, B, A_hat_split)\n",
    "            acc_iter = self.accuracy(X, self.train_sum, B_split, A)\n",
    "            err_iter = self.error(X, self.train_sum, B, A_hat_split)\n",
    "            print(list(acc_iter))\n",
    "#             error, error_star = sc.error(list(x_train.values()),train_sum,B_list,A_list)\n",
    "            print(list(err_iter))\n",
    "               \n",
    "            acc_ddsc.append(acc_iter)\n",
    "            err_ddsc.append(err_iter)\n",
    "            a_ddsc.append(np.linalg.norm(A_hat))\n",
    "            b_ddsc.append(np.linalg.norm(B_cat))\n",
    "\n",
    "            \n",
    "\n",
    "        self.acc_ddsc = acc_ddsc\n",
    "        self.err_ddsc = err_ddsc\n",
    "        self.a_ddsc = a_ddsc\n",
    "        self.b_ddsc = b_ddsc\n",
    "        return B_cat\n",
    "\n",
    "    def predict(self,A,B):\n",
    "        x = map(lambda x,y: x.dot(y),B,A)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localhour</th>\n",
       "      <th>use</th>\n",
       "      <th>air1</th>\n",
       "      <th>furnace1</th>\n",
       "      <th>dishwasher1</th>\n",
       "      <th>regrigerator1</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>1.194</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 01:00:00</td>\n",
       "      <td>1.185</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 02:00:00</td>\n",
       "      <td>1.307</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 03:00:00</td>\n",
       "      <td>1.515</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 04:00:00</td>\n",
       "      <td>1.175</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                localhour    use   air1  furnace1  dishwasher1  regrigerator1  \\\n",
       "house                                                                           \n",
       "2242  2014-01-01 00:00:00  1.194  0.032     0.013          0.0          0.083   \n",
       "2242  2014-01-01 01:00:00  1.185  0.032     0.271          0.0          0.078   \n",
       "2242  2014-01-01 02:00:00  1.307  0.032     0.305          0.0          0.087   \n",
       "2242  2014-01-01 03:00:00  1.515  0.031     0.648          0.0          0.109   \n",
       "2242  2014-01-01 04:00:00  1.175  0.032     0.408          0.0          0.092   \n",
       "\n",
       "       other  \n",
       "house         \n",
       "2242   1.066  \n",
       "2242   0.804  \n",
       "2242   0.883  \n",
       "2242   0.727  \n",
       "2242   0.643  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataprocess import read_data, format_data, split\n",
    "\n",
    "df, houses = read_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = format_data(df, houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2242     94   2034   2829   2974    135   2156    508   3273    898  ...  \\\n",
      "0   1.194  1.561  0.713  0.397  2.536  1.043  2.947  0.108  1.800  0.410  ...   \n",
      "1   1.185  1.421  0.658  0.381  1.795  0.158  1.460  0.102  5.010  0.488  ...   \n",
      "2   1.307  1.434  1.641  0.300  1.305  1.097  1.353  0.101  2.939  0.531  ...   \n",
      "3   1.515  1.283  1.397  0.262  0.368  0.715  1.836  0.101  0.080  0.222  ...   \n",
      "4   1.175  1.147  0.444  0.225  0.655  0.111  1.345  5.169  0.091  0.222  ...   \n",
      "5   1.132  0.244  0.377  0.189  0.403  0.712  1.570  2.633  0.132  0.193  ...   \n",
      "6   0.946  0.207  0.369  0.321  1.243  0.687  1.604  1.711  0.237  0.116  ...   \n",
      "7   1.240  0.195  0.696  0.193  0.400  0.139  0.329  1.095  0.132  0.051  ...   \n",
      "8   1.140  0.261  0.341  0.173  0.514  1.083  0.338  0.103  0.329  0.220  ...   \n",
      "9   1.841  0.286  0.129  0.297  1.831  0.104  0.177  1.290  0.246  0.250  ...   \n",
      "10  1.226  0.209  0.501  0.174  3.284  1.184  0.210  0.112  1.239  0.089  ...   \n",
      "11  2.165  0.368  0.198  0.174  0.572  0.229  0.345  0.152  0.564  0.640  ...   \n",
      "12  1.468  0.204  0.643  0.173  0.686  0.225  0.176  3.283  1.265  2.059  ...   \n",
      "13  1.857  0.300  1.295  0.176  3.299  0.176  0.232  0.325  0.908  0.346  ...   \n",
      "14  2.897  0.200  1.037  0.225  0.583  0.244  0.468  0.348  0.204  0.057  ...   \n",
      "15  3.787  0.443  0.772  0.314  0.445  0.075  0.343  0.449  0.891  0.100  ...   \n",
      "16  1.035  2.097  0.957  0.315  0.834  0.068  0.783  0.355  0.114  0.187  ...   \n",
      "17  1.671  0.591  0.138  0.285  0.670  0.127  0.390  0.485  0.202  0.141  ...   \n",
      "18  1.925  0.379  0.489  0.315  0.405  0.086  0.716  0.488  0.215  0.231  ...   \n",
      "19  4.453  0.754  1.796  0.310  2.114  0.144  1.108  0.641  0.197  0.388  ...   \n",
      "20  4.341  0.368  1.629  0.343  2.299  0.261  1.692  0.153  0.198  0.190  ...   \n",
      "21  4.006  1.657  1.538  0.337  2.052  0.302  5.640  0.148  0.946  0.360  ...   \n",
      "22  3.831  0.291  1.661  0.220  1.615  0.892  2.785  0.146  0.195  0.847  ...   \n",
      "23  4.320  0.388  1.523  0.189  2.356  0.335  0.487  0.146  0.230  0.199  ...   \n",
      "\n",
      "     3687   3678   3443   3721   3873   2004   3938   2171   2710   2845  \n",
      "0   1.107  1.167  0.135  0.511  0.163  0.555  0.177  2.177  6.749  1.160  \n",
      "1   1.717  0.521  0.096  0.636  0.268  0.504  0.082  1.058  2.181  1.087  \n",
      "2   1.010  0.649  1.300  1.736  0.163  0.503  0.082  0.343  1.345  0.951  \n",
      "3   0.987  0.133  0.086  0.155  0.154  0.460  0.187  1.398  3.884  0.481  \n",
      "4   0.634  0.217  0.134  0.053  0.051  0.535  0.083  0.420  2.015  0.450  \n",
      "5   0.298  0.112  2.204  0.074  0.334  0.525  0.209  0.276  0.504  0.345  \n",
      "6   0.444  0.180  0.134  0.092  0.058  0.405  0.232  0.563  1.898  0.353  \n",
      "7   0.288  0.382  0.283  0.340  0.058  0.540  0.299  0.159  4.033  0.666  \n",
      "8   0.353  0.114  0.349  0.159  0.146  0.662  0.277  0.160  6.443  0.332  \n",
      "9   0.442  1.676  0.294  0.699  0.814  0.476  0.287  0.160  2.682  0.726  \n",
      "10  0.463  1.581  0.266  0.224  0.195  0.454  0.108  2.314  0.885  0.406  \n",
      "11  0.842  0.111  1.442  0.141  0.105  0.471  0.143  1.366  0.695  0.422  \n",
      "12  0.286  0.518  0.313  0.219  0.210  0.574  0.082  2.262  0.826  0.578  \n",
      "13  0.703  0.345  0.447  0.394  0.106  0.583  0.083  4.804  0.717  0.578  \n",
      "14  0.318  1.274  0.255  1.583  0.654  0.455  0.082  2.245  0.833  0.811  \n",
      "15  0.518  0.299  5.923  0.310  2.394  0.433  0.179  0.971  0.901  0.552  \n",
      "16  0.530  0.459  0.483  0.164  0.543  0.483  0.126  4.570  2.232  0.394  \n",
      "17  0.189  0.368  0.330  0.049  0.156  0.501  0.082  0.310  0.960  0.280  \n",
      "18  0.179  1.394  0.284  1.265  0.589  0.409  0.207  0.408  1.233  0.706  \n",
      "19  0.626  0.927  0.421  1.877  0.684  0.606  1.050  0.923  1.779  1.617  \n",
      "20  0.774  1.016  0.397  0.268  0.548  0.472  0.769  0.667  1.554  5.643  \n",
      "21  0.851  0.511  0.341  0.176  0.743  0.550  0.504  0.645  6.403  1.182  \n",
      "22  0.986  0.341  0.371  0.193  0.309  0.344  1.722  3.534  6.814  1.732  \n",
      "23  1.093  0.802  0.216  1.629  0.337  0.515  0.881  1.669  0.713  2.743  \n",
      "\n",
      "[24 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "factor_n_t = 5 # heuristically determined\n",
    "\n",
    "timeframes = [14,30,60]\n",
    "timeframes = [48]\n",
    "# timeframes = [336] # 24*7*2\n",
    "#timeframes = [x*24 for x in timeframes]\n",
    "alphas = [0.0001]\n",
    "#alphas = [0.0001, 0.00001, 0.000001]\n",
    "portion = 0.5\n",
    "# Good values (t,n,alpha)\n",
    "# (14,40, alpha = 0.0001)\n",
    "# (336,800, alpha = 0.00001)\n",
    "# (720,,1400, alpha = )\n",
    "for timeframe, alpha in zip(timeframes,alphas):\n",
    "#     n = int(factor_n_t*timeframe)\n",
    "    n = 250 # number of basis function \n",
    "    x_train, x_test = split(d,portion,timeframe)\n",
    "# use in whole house disaggregation step\n",
    "    x_train_use = x_train.pop('use',None)\n",
    "    x_test_use = x_test.pop('use',None)\n",
    "    x_train_localhour = x_train.pop('localhour',None)\n",
    "    x_test_localhour = x_test.pop('localhour',None)\n",
    "    train_sum = sum(x_train.values())\n",
    "# algorithm starts\n",
    "\n",
    "\n",
    "print(train_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============started the pre-training============\n",
      "iter 1：A change =  41.0364\n",
      "iter 2：A change =   0.3077\n",
      "iter 3：A change =   0.3659\n",
      "iter 4：A change =   0.4519\n",
      "iter 5：A change =   0.5561\n",
      "iter 6：A change =   0.6586\n",
      "iter 7：A change =   0.7361\n",
      "iter 8：A change =   0.7723\n",
      "iter 9：A change =   0.7647\n",
      "iter 10：A change =   0.7232\n",
      "iter 11：A change =   0.6626\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 1：A change =  40.6844\n",
      "iter 2：A change =   0.5236\n",
      "iter 3：A change =   0.5506\n",
      "iter 4：A change =   0.5713\n",
      "iter 5：A change =   0.5839\n",
      "iter 6：A change =   0.5890\n",
      "iter 7：A change =   0.5889\n",
      "iter 8：A change =   0.5855\n",
      "iter 9：A change =   0.5805\n",
      "iter 10：A change =   0.5748\n",
      "iter 11：A change =   0.5689\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 1：A change =  42.0758\n",
      "iter 2：A change =   0.1015\n",
      "iter 3：A change =   0.1079\n",
      "iter 4：A change =   0.1216\n",
      "iter 5：A change =   0.1368\n",
      "iter 6：A change =   0.1491\n",
      "iter 7：A change =   0.1559\n",
      "iter 8：A change =   0.1565\n",
      "iter 9：A change =   0.1516\n",
      "iter 10：A change =   0.1426\n",
      "iter 11：A change =   0.1314\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 1：A change =  41.1946\n",
      "iter 2：A change =   0.0627\n",
      "iter 3：A change =   0.0647\n",
      "iter 4：A change =   0.0671\n",
      "iter 5：A change =   0.0702\n",
      "iter 6：A change =   0.0738\n",
      "iter 7：A change =   0.0776\n",
      "iter 8：A change =   0.0813\n",
      "iter 9：A change =   0.0846\n",
      "iter 10：A change =   0.0872\n",
      "iter 11：A change =   0.0890\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 1：A change =  37.3439\n",
      "iter 2：A change =   0.8778\n",
      "iter 3：A change =   0.9086\n",
      "iter 4：A change =   0.9499\n",
      "iter 5：A change =   0.9976\n",
      "iter 6：A change =   1.0485\n",
      "iter 7：A change =   1.1010\n",
      "iter 8：A change =   1.1540\n",
      "iter 9：A change =   1.2071\n",
      "iter 10：A change =   1.2599\n",
      "iter 11：A change =   1.3123\n",
      "Gone through one appliance.\n",
      "\n",
      "time of computations for Dictionary Learning with m = 21 and T = 24 took: 4.621s\n",
      "=============done pre_training==============\n",
      "[0.16582896872822744, 0.40579408793391847]\n",
      "[152.47382661347777, 152.47382661315314]\n",
      "step 1: DD change = 0.0826\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-319d80b891e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=============done pre_training==============\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Discriminative Disaggregation training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mB_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_use\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=================done DD==============\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Given test examples x_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d10a5a13ef95>\u001b[0m in \u001b[0;36mDD\u001b[0;34m(self, X_sum, B, A)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0macc_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0macc_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0merr_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;31m#             error, error_star = sc.error(list(x_train.values()),train_sum,B_list,A_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d10a5a13ef95>\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, x, x_sum, B, A)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mA_last_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mA_last_error_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_last_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0merror_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_last_error_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d10a5a13ef95>\u001b[0m in \u001b[0;36mF\u001b[0;34m(self, X_sum, B, A)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# B: basis function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# A: activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mB_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mA_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/librosa/decompose.py\u001b[0m in \u001b[0;36mdecompose\u001b[0;34m(S, n_components, transformer, sort, fit, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_n_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_max_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m             n_jobs=self.n_jobs, positive=self.positive_code)\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_sign\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36msparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    316\u001b[0m                               \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                               positive=positive)\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36m_sparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, regularization, copy_cov, init, max_iter, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mnew_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    749\u001b[0m                           \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                           \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                           check_input=False)\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mdual_gaps_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    470\u001b[0m             model = cd_fast.enet_coordinate_descent_gram(\n\u001b[1;32m    471\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                 tol, rng, random, positive)\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mprecompute\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             model = cd_fast.enet_coordinate_descent(\n",
      "\u001b[0;32msklearn/linear_model/_cd_fast.pyx\u001b[0m in \u001b[0;36msklearn.linear_model._cd_fast.enet_coordinate_descent_gram\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "factor_n_t = 5 # heuristically determined\n",
    "\n",
    "timeframes = [14,30,60]\n",
    "timeframes = [48]\n",
    "# timeframes = [336] # 24*7*2\n",
    "#timeframes = [x*24 for x in timeframes]\n",
    "alphas = [0.0001]\n",
    "#alphas = [0.0001, 0.00001, 0.000001]\n",
    "portion = 0.5\n",
    "# Good values (t,n,alpha)\n",
    "# (14,40, alpha = 0.0001)\n",
    "# (336,800, alpha = 0.00001)\n",
    "# (720,,1400, alpha = )\n",
    "for timeframe, alpha in zip(timeframes,alphas):\n",
    "#     n = int(factor_n_t*timeframe)\n",
    "    n = 250 # number of basis function \n",
    "    x_train, x_test = split(d,portion,timeframe)\n",
    "# use in whole house disaggregation step\n",
    "    x_train_use = x_train.pop('use',None)\n",
    "    x_test_use = x_test.pop('use',None)\n",
    "    x_train_localhour = x_train.pop('localhour',None)\n",
    "    x_test_localhour = x_test.pop('localhour',None)\n",
    "# algorithm starts\n",
    "\n",
    "    # parameters\n",
    "    train_set = x_train\n",
    "    test_set = x_test\n",
    "    train_sum = sum(x_train.values())\n",
    "    k = len(x_train.keys())\n",
    "    T,m = x_train[list(x_train.keys())[0]].shape\n",
    "    rp = 0.0005\n",
    "    epsilon = 0.001\n",
    "    alpha = 0.0001\n",
    "    steps = 10# steps must be higher than k\n",
    "    # get data\n",
    "    \n",
    "\n",
    "    # Sparse Coding pre_training\n",
    "    sc = DDSC(train_set,train_sum,alpha,epsilon,rp,steps,n,m,T,k)\n",
    "    print(\"============started the pre-training============\")\n",
    "    A_list,B_list = sc.pre_training(x_train.values())\n",
    "    print(\"=============done pre_training==============\")\n",
    "    # Discriminative Disaggregation training\n",
    "    B_cat = sc.DD(x_train_use.values,B_list,A_list)\n",
    "    print(\"=================done DD==============\")\n",
    "    # Given test examples x_test\n",
    "    A_prime = sc.F(x_test_use.values,B_cat,A=np.vstack(A_list))\n",
    "    A_last = np.split(A_prime,k,axis=0)\n",
    "    x_predict = sc.predict(A_last,B_list)\n",
    "    print(\"the shape of the first predicted appliances is :%s\" %(np.asarray(list(x_predict)[0]).shape,))\n",
    "    x_predict_sum = sum(x_predict)\n",
    "    \n",
    "    # energy disaggregation accuracy\n",
    "    acc = sc.accuracy(x_train.values(),train_sum,B_list,A_last)\n",
    "    # energy disaggregation error\n",
    "    error, error_star = sc.error(x_train.values(),train_sum,B_list,A_list)\n",
    "    print(\"error: %s, error_star: %s\" % (error, error_star))\n",
    "    acc_nnsc, acc_ddsc = sc.get_accuracy_plot()\n",
    "    err_nnsc, err_ddsc = sc.get_error_plot()\n",
    "    # plotting acc/err\n",
    "    a_nnsc, a_ddsc = sc.get_a()\n",
    "    b_nnsc, b_ddsc = sc.get_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_nnddsc, acc_ddddsc = sc.get_accuracy_plot()\n",
    "# for acc in acc_ddddsc:\n",
    "#     print(acc[1])\n",
    "# res = list(zip(*acc_ddddsc)) \n",
    "# plt.plot(res[1])\n",
    "err_nnddsc, err_ddddsc = sc.get_error_plot()\n",
    "res_err = list(zip(*err_ddddsc)) \n",
    "plt.plot(res_err[0])\n",
    "plt.show()\n",
    "\n",
    "acc_nnsc, acc_ddsc = sc.get_accuracy_plot()\n",
    "res_acc = list(zip(*acc_ddsc)) \n",
    "plt.plot(res_acc[0])\n",
    "plt.show()\n",
    "# err_nnddsc, err_ddddsc = sc.get_error_plot()\n",
    "\n",
    "\n",
    "# # plotting acc/err\n",
    "# # a_nnsc, a_ddsc = sc.get_a()\n",
    "# # b_nnsc, b_ddsc = sc.get_b()\n",
    "# # error, error_star = sc.error(list(x_train.values()),train_sum,B_list,A_list)\n",
    "# # print(\"error: %s, error_star: %s\" % (sum(error),sum(error_star)))\n",
    "\n",
    "# for error, error_star in err_ddddsc:\n",
    "#     print(sum(error.value()))\n",
    "# # print(err_ddddsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = sc.predict(A_last,B_list)\n",
    "print(\"the shape of the first predicted appliances is :%s\" %(np.asarray(list(x_predict)[0]).shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_predict = sc.predict(A_last,B_list)\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "\n",
    "print(np.asarray(list(x_predict)[0])[0:,house])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.style.use('classic')\n",
    "# row and column sharing\n",
    "house = 10\n",
    "\n",
    "pie_chart_true = []\n",
    "pie_chart_pred = []\n",
    "\n",
    "f, ((ax1, ax2, ax3, ax4, ax5, ax6)) = plt.subplots(6, 1, sharex='col', sharey='row', figsize=(16,12))\n",
    "x = range(x_train[list(x_train.keys())[0]].shape[0])\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "#===========whole home============\n",
    "y_use_true = np.asarray(x_test_use)[0:,house]\n",
    "ax1.plot(x, y_use_true, color='b',label='Actual energy')\n",
    "y_use_pred = [-1]*x_train[list(x_train.keys())[0]].shape[0]\n",
    "ax1.plot(x, y_use_pred, color='r', label='Predicted')\n",
    "ax1.set_ylim([0,7])\n",
    "ax1.set_ylabel('Whole Home')\n",
    "ax1.legend()\n",
    "\n",
    "#===========regrigerator============\n",
    "y_ref_true = np.asarray(x_test[list(x_test.keys())[0]])[0:,house]\n",
    "ax2.plot(x, y_ref_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_ref_pred = np.asarray(list(x_predict)[0])[0:,house]\n",
    "ax2.plot(x, y_ref_pred, color='r')\n",
    "#ax2.get_yaxis().set_visible(False)\n",
    "ax2.set_ylabel('Refrigerator')\n",
    "ax2.set_ylim([0,0.05])\n",
    "\n",
    "\n",
    "#===========dishwasher============\n",
    "y_dish_true = np.asarray(x_test[list(x_test.keys())[1]])[0:,house]\n",
    "ax3.plot(x, y_dish_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_dish_pred = np.asarray(list(x_predict)[1])[0:,house]\n",
    "ax3.plot(x,y_dish_pred, color='r')\n",
    "#ax3.get_yaxis().set_visible(False)\n",
    "ax3.set_ylabel('Dishwasher')\n",
    "#ax3.set_ylim(-0.00001)\n",
    "\n",
    "#===========furnace============\n",
    "y_fur_true = np.asarray(x_test[list(x_test.keys())[2]])[0:,house]\n",
    "ax4.plot(x, y_fur_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_fur_pred = np.asarray(list(x_predict)[2])[0:,house]\n",
    "ax4.plot(x,y_fur_pred, color='r')\n",
    "#ax4.get_yaxis().set_visible(False)\n",
    "ax4.set_ylabel('Furnace')\n",
    "# ax4.set_ylim(-0.05, 0.05)\n",
    "\n",
    "#===========Air============\n",
    "y_air_true = np.asarray(x_test[list(x_test.keys())[3]])[0:,house]\n",
    "ax5.plot(x, y_air_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_air_pred = np.asarray(list(x_predict)[3])[0:,house]\n",
    "ax5.plot(x, y_air_pred, color='r')\n",
    "#ax5.get_yaxis().set_visible(False)\n",
    "ax5.set_ylabel('Air')\n",
    "# ax5.set_xlabel('Hours')\n",
    "\n",
    "#===========others============\n",
    "y_other_true = np.asarray(x_test[list(x_test.keys())[4]])[0:,house]\n",
    "ax6.plot(x, y_other_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_other_pred = np.asarray(list(x_predict)[4])[0:,house]\n",
    "ax6.plot(x, y_other_pred, color='r')\n",
    "#ax5.get_yaxis().set_visible(False)\n",
    "ax6.set_ylabel('Others')\n",
    "ax6.set_xlabel('Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart_true = [y_ref_true.sum(), y_dish_true.sum(), y_fur_true.sum(), y_air_true.sum(), y_other_true.sum()]\n",
    "pie_chart_pred = [y_ref_pred.sum(), y_dish_pred.sum(), y_fur_pred.sum(), y_air_pred.sum(), y_other_pred.sum()]\n",
    "\n",
    "plt.style.use('classic')\n",
    "\n",
    "def pie_chart(subplot, pie_chart, labels):\n",
    "    # The slices will be ordered and plotted counter-clockwise.\n",
    "    ## --- Plotting the true-piechart\n",
    "    pie_chart_sum = sum(pie_chart)\n",
    "    pie_chart = list(map(lambda x: x/pie_chart_sum,pie_chart))\n",
    "    cmap = plt.cm.prism\n",
    "    colors = cmap(np.linspace(0., 1., len(pie_chart)))\n",
    "    pie_wedge_collection = subplot.pie(pie_chart, colors=colors, labels=labels, labeldistance=1.03)\n",
    "\n",
    "    for pie_wedge in pie_wedge_collection[0]:\n",
    "        pie_wedge.set_edgecolor('white')\n",
    "    # Set aspect ratio to be equal so that pie is drawn as a circle.\n",
    "    \n",
    "    \n",
    "f, ((axes1, axes2)) = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(16,16))\n",
    "\n",
    "labels = x_test.keys()\n",
    "print(labels)\n",
    "pie_chart(axes1,pie_chart_true,labels)\n",
    "axes1.set_title('True usage')\n",
    "pie_chart(axes2,pie_chart_pred,labels)\n",
    "axes2.set_title('Predicted usage')\n",
    "# axes2.text(0.95, 0.01, 'Accuracy of ' + str(round(sc.acc[0],1)), verticalalignment='center', horizontalalignment='right', transform=axes2.transAxes, color='black', fontsize=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the B matrices (basis functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "# row and column sharing\n",
    "f, ((ax1, ax2, ax3)) = plt.subplots(3, 1, sharex='col', sharey='row', figsize=(16,12))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "B_list[0] = B_list[0]/np.sum(B_list[0],axis=1)[:,None]  # Normalize\n",
    "ax1.pcolor(B_list[0], cmap = cm.Greys_r)\n",
    "B_list[1] = B_list[1]/np.sum(B_list[1],axis=1)[:,None]  # Normalize\n",
    "ax2.pcolor(B_list[1], cmap = cm.Greys_r)\n",
    "B_list[2] = B_list[2]/np.sum(B_list[2],axis=1)[:,None]  # Normalize\n",
    "ax3.pcolor(B_list[2], cmap = cm.Greys_r)\n",
    "\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax2.get_xaxis().set_visible(False)\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "ax3.get_xaxis().set_visible(False)\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "\n",
    "# plt.savefig(figure_directory+'basis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "# row and column sharing\n",
    "f, ((ax1, ax2, ax3)) = plt.subplots(3, 1, sharex='col', sharey='row', figsize=(16,12))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "for base in range(7):\n",
    "    ax1.plot(range(n),B_list[0][base,0:])\n",
    "    ax2.plot(range(n),B_list[1][base,0:])\n",
    "    ax3.plot(range(n),B_list[2][base,0:])\n",
    "\n",
    "ax1.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "ax1.set_ylim([0,0.04])\n",
    "ax1.set_ylabel('Refrigerator')\n",
    "ax2.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "ax2.set_ylim([0,0.06])\n",
    "ax2.set_ylabel('Dishwasher')\n",
    "ax3.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "ax3.set_ylim([0,0.02])\n",
    "ax3.set_ylabel('Furnace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
