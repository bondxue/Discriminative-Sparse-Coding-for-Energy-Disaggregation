{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminative Sparse Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import librosa\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import SparseCoder,DictionaryLearning\n",
    "from sklearn import cluster\n",
    "# from lightning.regression import CDRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDSC():\n",
    "    def __init__(self,train_set,train_sum,gradient_step_size,epsilon,regularization_parameter,steps,n_components,m,T,k):\n",
    "        \"\"\"\n",
    "        Either form is acceptable, but the two should not be mixed. Choose one\n",
    "        convention to document the __init__ method and be consistent with it.\n",
    "\n",
    "        Args:\n",
    "          gradient_step_size (float): gradiant rate for the convergence step for DD (4b).\n",
    "          epsilon (float): the gradient stepsize of the pre-training (2b).\n",
    "          regularization_parameter (float) : weight of penalty function.\n",
    "          steps (int) : interations to be performed for the convergence part\n",
    "          param2 (list of str): Description of `param2`. Multiple\n",
    "            lines are supported.\n",
    "          param3 (int, optional): Description of `param3`, defaults to 0.\n",
    "        \"\"\"\n",
    "        self.train_set = train_set\n",
    "        self.train_sum = train_sum\n",
    "        self.alpha = gradient_step_size\n",
    "        self.epsilon = epsilon\n",
    "        self.rp = regularization_parameter\n",
    "        self.steps = steps\n",
    "        self.n = n_components\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.k = k\n",
    "\n",
    "        '''\n",
    "        Instances that can be used for plotting\n",
    "        '''\n",
    "        self.acc_nnsc = None\n",
    "        self.err_nnsc = None\n",
    "        self.acc_ddsc = None\n",
    "        self.err_ddsc = None\n",
    "        self.a_nnsc = None\n",
    "        self.b_nnsc = None\n",
    "        self.a_ddsc = None\n",
    "        self.b_ddsc = None\n",
    "\n",
    "\n",
    "#=====================================================================\n",
    "# will initiualize the matrices A,B with positive values and scale\n",
    "# columns of B s.t b(j) = 1\n",
    "    def _initialization(self):\n",
    "\n",
    "        a = np.random.random((self.n,self.m))\n",
    "        b = np.random.random((self.T,self.n))\n",
    "\n",
    "        # scale columns s.t. b_i^(j) = 1\n",
    "        b /= sum(b)\n",
    "        return a,b\n",
    "\n",
    "    # add random positive number to A,B\n",
    "    # scale columns of b(j)\n",
    "\n",
    "#=====================================================================\n",
    "    def accuracy(self,x,x_sum,B,A):\n",
    "        '''\n",
    "        Everything needs to be in lists of ndarrays\n",
    "        of the components\n",
    "        '''\n",
    "        B_cat = np.hstack(B)\n",
    "        A_cat = np.vstack(A)\n",
    "\n",
    "        A_prime = self.F(x_sum.values,B_cat,A=A_cat)\n",
    "        A_last = np.split(A_prime,self.k,axis=0)\n",
    "        x_predict = self.predict(A_last,B)\n",
    "        acc_numerator = (map(lambda i: (np.minimum( (B[i].dot(A_last[i])).sum(), (sum(list(x)[i].sum())))),\n",
    "                        range(len(B))))\n",
    "        acc_denominator = sum(x_predict).sum()\n",
    "        acc = sum(acc_numerator) / acc_denominator\n",
    "        \n",
    "        acc_numerator = (map(lambda i: (np.minimum( (B[i].dot(A_last[i])).sum() ,\n",
    "                        (sum(list(x)[i].sum())))) ,\n",
    "                        range(len(B))))\n",
    "        print(sum(acc_numerator))\n",
    "        acc_denominator = x_sum.values.sum()\n",
    "        acc_star = sum(acc_numerator) / acc_denominator\n",
    "        return acc, acc_star\n",
    "\n",
    "    def get_accuracy_plot(self):\n",
    "        return self.acc_nnsc, self.acc_ddsc\n",
    "\n",
    "    def get_error_plot(self):\n",
    "        return self.err_nnsc, self.err_ddsc\n",
    "\n",
    "    def get_a(self):\n",
    "        return self.a_nnsc, self.a_ddsc\n",
    "\n",
    "    def get_b(self):\n",
    "        return self.b_nnsc, self.b_ddsc\n",
    "\n",
    "    def error(self,x,x_sum,B,A):\n",
    "        '''\n",
    "        Error for the whole disaggregation part within list, sum the list to get\n",
    "        the resulting disaggregation\n",
    "        Parameters : must have x_train as x\n",
    "        '''\n",
    "        B_cat = np.hstack(B)\n",
    "        A_cat = np.vstack(A)\n",
    "        \n",
    "        error = (map(lambda i: ((1.0/2.0)*np.linalg.norm( (x[i] - B[i].dot(A[i]))**2)), range(len(B))))\n",
    "        \n",
    "        A_last_error = self.F(x_sum.values,B_cat,A_cat)\n",
    "        A_last_error_list = np.split(A_last_error,self.k,axis=0)\n",
    "        error_star = (map(lambda i: ((1.0/2.0)*np.linalg.norm((x[i] - B[i].dot(A_last_error_list[i]))**2)),range(len(B))))\n",
    "        \n",
    "        return error, error_star\n",
    "\n",
    "    def pre_training(self,x):\n",
    "        # TODO : implement s.t. conditions and frobenius norm to the options\n",
    "        tic = time.time()\n",
    "        #the NON NEGATIVE SPARSE CODING\n",
    "        A_list,B_list = self.nnsc(x)\n",
    "\n",
    "        tac = time.time()\n",
    "        t = tac - tic\n",
    "        print('time of computations for Dictionary Learning with m: %s and T: %s took: %f' %(self.m,self.T,t))\n",
    "        return A_list,B_list\n",
    "    \n",
    "#=====================================================================\n",
    "    # using only the positive values\n",
    "    @staticmethod\n",
    "    def _pos_constraint(a):\n",
    "        indices = np.where(a < 0.0)\n",
    "        a[indices] = 0.0\n",
    "        return a\n",
    "    \n",
    "#=====================================================================\n",
    "    def nnsc(self,appliances):\n",
    "        '''\n",
    "        Method as in NNSC from nonnegative sparse coding finland.\n",
    "        from P.Hoyer\n",
    "        TODO:\n",
    "        implement the coordinate descent algorithm, as of now we are using         gradient descent (not as efficient)\n",
    "        Also create multiple ndarrays that we take the argmin for.\n",
    "        '''\n",
    "        epsilon = 0.01\n",
    "        acc_nnsc = []\n",
    "        err_nnsc = []\n",
    "        a_nnsc = []\n",
    "        b_nnsc = []\n",
    "        # used for F\n",
    "        x_train_sum = self.train_set.values()\n",
    "        A_list = []\n",
    "        B_list = []\n",
    "        for x in appliances:\n",
    "            # 1 \n",
    "            A0, B0 = self._initialization() # initialization \n",
    "            Ap, Bp = A0, B0\n",
    "            Ap1, Bp1 = Ap, Bp # record previous step Ap, Bp\n",
    "            t = 0\n",
    "            change_A = 1.0\n",
    "            while t <= self.steps and change_A >= self.epsilon:\n",
    "                # 2a\n",
    "                Bp = Bp - self.alpha*np.dot((np.dot(Bp,Ap) - x),Ap.T)\n",
    "                # 2b\n",
    "                Ap = self._pos_constraint(Ap)\n",
    "                # 2c\n",
    "                Bp /= sum(Bp)\n",
    "                # element wise division\n",
    "                dot2 = np.divide(np.dot(Bp.T,x),(np.dot(np.dot(Bp.T,Bp),Ap) + self.rp))\n",
    "                # 2d\n",
    "                Ap = np.multiply(Ap,dot2)\n",
    "\n",
    "                change_A = np.linalg.norm(Ap - Ap1)\n",
    "                change_B = np.linalg.norm(Bp - Bp1)\n",
    "                Ap1, Bp1 = Ap, Bp\n",
    "                t += 1\n",
    "\n",
    "                print(\"iter {t}ï¼šA change = {a:8.4f},  B change = {b:8.4f}\".format(t=t, a=change_A, b=change_B))\n",
    "\n",
    "            print(\"Gone through one appliance\")\n",
    "            A_list.append(Ap)\n",
    "            B_list.append(Bp)\n",
    "\n",
    "\n",
    "        # for thesis\n",
    "        acc_iter = self.accuracy(x_train_sum,self.train_sum,B_list,A_list)\n",
    "        err_iter = self.error(x_train_sum,self.train_sum,B_list,A_list)\n",
    "        acc_nnsc.append(acc_iter)\n",
    "        err_nnsc.append(err_iter)\n",
    "        # append norm of matrices\n",
    "        a_nnsc.append(np.linalg.norm(sum(A_list)))\n",
    "        b_nnsc.append(np.linalg.norm(sum(B_list)))\n",
    "        print(b_nnsc)\n",
    "\n",
    "        self.acc_nnsc = acc_nnsc\n",
    "        self.err_nnsc = err_nnsc\n",
    "        self.a_nnsc = a_nnsc\n",
    "        self.b_nnsc = b_nnsc\n",
    "        return A_list,B_list\n",
    "    \n",
    "#=====================================================================\n",
    "    def F(self,x,B,x_train=None,A=None,rp_tep=False,rp_gl=False):\n",
    "        '''\n",
    "        input is lists of the elements\n",
    "        output list of elements\n",
    "        '''\n",
    "        # 4b\n",
    "        B = np.asarray(B)\n",
    "        A = np.asarray(A)\n",
    "        coder = SparseCoder(dictionary=B.T,\n",
    "                            transform_alpha=self.rp, transform_algorithm='lasso_cd')\n",
    "        comps, acts = librosa.decompose.decompose(x,transformer=coder)\n",
    "        acts = self._pos_constraint(acts)\n",
    "\n",
    "        return acts\n",
    "    \n",
    "#=====================================================================\n",
    "    def DD(self,x,B,A):\n",
    "        '''\n",
    "        Taking the parameters as x_train_use and discriminate over the\n",
    "        entire region\n",
    "        '''\n",
    "        # 3.\n",
    "        A_star = np.vstack(A)\n",
    "        B_cat = np.hstack(B)\n",
    "        change = 1\n",
    "        t = 0\n",
    "        acc_ddsc = []\n",
    "        err_ddsc = []\n",
    "        a_ddsc = []\n",
    "        b_ddsc = []\n",
    "        x_train_sum = self.train_set.values()\n",
    "        while t <= self.steps and self.epsilon <= change:\n",
    "            B_cat_p = B_cat\n",
    "            # 4a\n",
    "            acts = self.F(x,B_cat,A=A_star)\n",
    "            # 4b\n",
    "            B_cat = (B_cat-self.alpha*((x-B_cat.dot(acts))\n",
    "                     .dot(acts.T) - (x-B_cat.dot(A_star)).dot(A_star.T)))\n",
    "            # 4c\n",
    "            # scale columns s.t. b_i^(j) = 1\n",
    "            B_cat = self._pos_constraint(B_cat)\n",
    "            B_cat /= sum(B_cat)\n",
    "\n",
    "            # convergence check\n",
    "            acts_split = np.split(acts,self.k,axis=0)\n",
    "            B_split = np.split(B_cat,self.k,axis=1)\n",
    "            acc_iter = self.accuracy(x_train_sum,self.train_sum,B,acts_split)\n",
    "            acc_iter = self.accuracy(x_train_sum,self.train_sum,B_split,A)\n",
    "            err_iter = self.error(x_train_sum,self.train_sum,B,acts_split)\n",
    "            acc_ddsc.append(acc_iter)\n",
    "            err_ddsc.append(err_iter)\n",
    "            a_ddsc.append(np.linalg.norm(acts))\n",
    "            b_ddsc.append(np.linalg.norm(B_cat))\n",
    "\n",
    "            change = np.linalg.norm(B_cat - B_cat_p)\n",
    "            t += 1\n",
    "            print(\"step {t}: DD change = {c:.4f}\".format(t=t, c=change))\n",
    "\n",
    "        self.acc_ddsc = acc_ddsc\n",
    "        self.err_ddsc = err_ddsc\n",
    "        self.a_ddsc = a_ddsc\n",
    "        self.b_ddsc = b_ddsc\n",
    "        return B_cat\n",
    "\n",
    "#=====================================================================\n",
    "    def predict(self,A,B):\n",
    "        x = map(lambda x,y: x.dot(y),B,A)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.random.random((3, 2))\n",
    "# b /= sum(b)\n",
    "b \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localhour</th>\n",
       "      <th>use</th>\n",
       "      <th>air1</th>\n",
       "      <th>furnace1</th>\n",
       "      <th>dishwasher1</th>\n",
       "      <th>regrigerator1</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2014-01-01 01:00:00</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2014-01-01 02:00:00</td>\n",
       "      <td>1.097</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2014-01-01 03:00:00</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2014-01-01 04:00:00</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                localhour    use   air1  furnace1  dishwasher1  regrigerator1  \\\n",
       "house                                                                           \n",
       "135   2014-01-01 00:00:00  1.043  0.840     0.064          0.0            0.0   \n",
       "135   2014-01-01 01:00:00  0.158  0.000     0.009          0.0            0.0   \n",
       "135   2014-01-01 02:00:00  1.097  0.759     0.060          0.0            0.0   \n",
       "135   2014-01-01 03:00:00  0.715  0.522     0.045          0.0            0.0   \n",
       "135   2014-01-01 04:00:00  0.111  0.000     0.009          0.0            0.0   \n",
       "\n",
       "       other  \n",
       "house         \n",
       "135    0.139  \n",
       "135    0.149  \n",
       "135    0.278  \n",
       "135    0.148  \n",
       "135    0.102  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataprocess import read_data, format_data, split\n",
    "\n",
    "df, houses = read_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = format_data(df, houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started the pre-training\n",
      "iter 1ï¼šA change =  41.1339,  B change =   0.2695\n",
      "iter 2ï¼šA change =   0.2945,  B change =   0.0004\n",
      "Gone through one appliance\n",
      "iter 1ï¼šA change =  40.0657,  B change =   0.2594\n",
      "iter 2ï¼šA change =   0.5038,  B change =   0.0008\n",
      "Gone through one appliance\n",
      "iter 1ï¼šA change =  40.8675,  B change =   0.2673\n",
      "iter 2ï¼šA change =   0.0987,  B change =   0.0000\n",
      "Gone through one appliance\n",
      "iter 1ï¼šA change =  40.3684,  B change =   0.2595\n",
      "iter 2ï¼šA change =   0.0623,  B change =   0.0000\n",
      "Gone through one appliance\n",
      "iter 1ï¼šA change =  35.9622,  B change =   0.2297\n",
      "iter 2ï¼šA change =   0.8503,  B change =   0.0058\n",
      "Gone through one appliance\n",
      "153.44112139802453\n",
      "[16.465695334091865]\n",
      "time of computations for Dictionary Learning with m: 21 and T: 24 took: 4.601334\n",
      "done pre_training\n",
      "153.44112139802453\n",
      "155.81609132034907\n",
      "step 1: DD change = 0.1713\n",
      "153.44112139802453\n",
      "159.91228736489435\n",
      "step 2: DD change = 0.0726\n",
      "done DD\n",
      "the shape of the first predicted appliances is :(24, 21)\n",
      "153.44112139802453\n"
     ]
    }
   ],
   "source": [
    "factor_n_t = 5 # heuristically determined\n",
    "\n",
    "timeframes = [14,30,60]\n",
    "timeframes = [48]\n",
    "#timeframes = [x*24 for x in timeframes]\n",
    "alphas = [0.0001]\n",
    "#alphas = [0.0001, 0.00001, 0.000001]\n",
    "portion = 0.5\n",
    "# Good values (t,n,alpha)\n",
    "# (14,40, alpha = 0.0001)\n",
    "# (336,800, alpha = 0.00001)\n",
    "# (720,,1400, alpha = )\n",
    "for timeframe, alpha in zip(timeframes,alphas):\n",
    "    n = int(factor_n_t*timeframe)\n",
    "    x_train, x_test = split(d,portion,timeframe)\n",
    "# use in whole house disaggregation step\n",
    "    x_train_use = x_train.pop('use',None)\n",
    "    x_test_use = x_test.pop('use',None)\n",
    "    x_train_localhour = x_train.pop('localhour',None)\n",
    "    x_test_localhour = x_test.pop('localhour',None)\n",
    "# algorithm starts\n",
    "\n",
    "    # parameters\n",
    "    train_set = x_train\n",
    "    test_set = x_test\n",
    "    train_sum = sum(x_train.values())\n",
    "    k = len(x_train.keys())\n",
    "    T,m = x_train[list(x_train.keys())[0]].shape\n",
    "    rp = 0.0005\n",
    "    epsilon = 0.001\n",
    "    alpha = 0.0001\n",
    "    steps = 1 # steps must be higher than k\n",
    "    # get data\n",
    "    n_components = n\n",
    "\n",
    "    # Sparse Coding pre_training\n",
    "    sc = DDSC(train_set,train_sum,alpha,epsilon,rp,steps,n_components,m,T,k)\n",
    "    print(\"started the pre-training\")\n",
    "    A_list,B_list = sc.pre_training(x_train.values())\n",
    "    print(\"done pre_training\")\n",
    "    # Discriminative Disaggregation training\n",
    "    B_cat = sc.DD(x_train_use.values,B_list,A_list)\n",
    "    print(\"done DD\")\n",
    "    # Given test examples x_test\n",
    "    A_prime = sc.F(x_test_use.values,B_cat,A=np.vstack(A_list))\n",
    "    A_last = np.split(A_prime,k,axis=0)\n",
    "    x_predict = sc.predict(A_last,B_list)\n",
    "    print(\"the shape of the first predicted appliances is :%s\" %(np.asarray(list(x_predict)[0]).shape,))\n",
    "    x_predict_sum = sum(x_predict)\n",
    "    \n",
    "    # energy disaggregation accuracy\n",
    "    acc = sc.accuracy(x_train.values(),train_sum,B_list,A_last)\n",
    "    # energy disaggregation error\n",
    "    error, error_star = sc.error(list(x_train.values()),train_sum,B_list,A_list)\n",
    "#     print(\"error: %s, error_star: %s\" % (sum(error),sum(error_star)))\n",
    "    acc_nnsc, acc_ddsc = sc.get_accuracy_plot()\n",
    "    err_nnsc, err_ddsc = sc.get_error_plot()\n",
    "    # plotting acc/err\n",
    "    a_nnsc, a_ddsc = sc.get_a()\n",
    "    b_nnsc, b_ddsc = sc.get_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error, error_star = sc.error(x_train.values(),train_sum,B_list,A_list)\n",
    "error = (map(lambda i: ((1.0/2.0)*np.linalg.norm( (x[i] - B[i].dot(A[i]))**2)),range(3)))\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = sc.predict(A_last,B_list)\n",
    "print(\"the shape of the first predicted appliances is :%s\" %(np.asarray(list(x_predict)[0]).shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_predict = sc.predict(A_last,B_list)\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "\n",
    "print(np.asarray(list(x_predict)[0])[0:,house])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row and column sharing\n",
    "house = 0\n",
    "f, ((ax1, ax2, ax3, ax4, ax5)) = plt.subplots(5, 1, sharex='col', sharey='row', figsize=(16,12))\n",
    "x = range(x_train[list(x_train.keys())[0]].shape[0])\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "y = np.asarray(x_test_use)[0:,house]\n",
    "ax1.plot(x, y, color='b',label='Actual energy')\n",
    "y=[-1]*x_train[list(x_train.keys())[0]].shape[0]\n",
    "# ax1.plot(x, y, color='r', label='Predicted')\n",
    "#ax1.set_ylim([0,2])\n",
    "ax1.set_ylabel('Whole Home')\n",
    "ax1.legend()\n",
    "#\n",
    "y = np.asarray(x_test[list(x_test.keys())[0]])[0:,house]\n",
    "ax2.plot(x, y, color='b')\n",
    "\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y = np.asarray(list(x_predict)[0])[0:,house]\n",
    "\n",
    "ax2.plot(x , y, color='r', linewidth=2, label='Predicted')\n",
    "#ax2.get_yaxis().set_visible(False)\n",
    "ax2.set_ylabel('Refrigerator')\n",
    "ax2.set_ylim(-0.01)\n",
    "ax2.legend()\n",
    "##\n",
    "y = np.asarray(x_test[list(x_test.keys())[1]])[0:,house]\n",
    "ax3.plot(x, y, color='b', linewidth=2)\n",
    "\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y = np.asarray(list(x_predict)[1])[0:,house]\n",
    "ax3.plot(x,y, color='r', linewidth=2)\n",
    "#ax3.get_yaxis().set_visible(False)\n",
    "ax3.set_ylabel('Dishwasher')\n",
    "#ax3.set_ylim(-0.00001)\n",
    "\n",
    "##\n",
    "y = np.asarray(x_test[list(x_test.keys())[2]])[0:,house]\n",
    "ax4.plot(x, y, color='b')\n",
    "\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y = np.asarray(list(x_predict)[2])[0:,house]\n",
    "print(y)\n",
    "ax4.plot(x,y, color='r')\n",
    "#ax4.get_yaxis().set_visible(False)\n",
    "ax4.set_ylabel('Furnace')\n",
    "# ax4.set_ylim(-0.05, 0.05)\n",
    "##\n",
    "y = np.asarray(x_test[list(x_test.keys())[3]])[0:,house]\n",
    "ax5.plot(x, y, color='b')\n",
    "\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y = np.asarray(list(x_predict)[3])[0:,house]\n",
    "ax5.plot(x,y, color='r')\n",
    "#ax5.get_yaxis().set_visible(False)\n",
    "ax5.set_ylabel('Air')\n",
    "ax5.set_xlabel('Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
