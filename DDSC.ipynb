{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminative Sparse Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import librosa\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import SparseCoder,DictionaryLearning\n",
    "from sklearn import cluster\n",
    "# from lightning.regression import CDRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDSC():\n",
    "    def __init__(self, train_set, train_sum, alpha, \n",
    "                 epsilon, reg_lambda, steps, n, m, T, k):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            train_set: dict of X_i matrix with dim T*m for each individual appliance i \n",
    "            train_sum: dataframe of X_sum aggregated matrix T*m \n",
    "            alpha: gradiant rate for the convergence step for DD (4b).\n",
    "            epsilon: gradient stepsize of the pre-training (2e) ||A_t+1 - A_t||< epsilon \n",
    "            reg_lambda: reguarization weight of penalty function\n",
    "            steps: interations to be performed for the convergence part\n",
    "            n: number of basis functions \n",
    "            m: number of features (households)\n",
    "            T: number of samples (hours)\n",
    "            k: number of applicances i (1, k)\n",
    "        \"\"\"\n",
    "        self.train_set = train_set.values()\n",
    "        self.train_sum = train_sum.values\n",
    "        self.alpha = alpha \n",
    "        self.epsilon = epsilon\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.steps = steps\n",
    "        self.n = n \n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.k = k\n",
    "        \n",
    "        # ======= Instances that can be used for plotting =====\n",
    "        self.acc_nnsc = None\n",
    "        self.err_nnsc = None\n",
    "        self.acc_ddsc = None\n",
    "        self.err_ddsc = None\n",
    "        \n",
    "        self.a_nnsc = None\n",
    "        self.b_nnsc = None\n",
    "        self.a_ddsc = None\n",
    "        self.b_ddsc = None\n",
    "\n",
    "    def _initialization(self):\n",
    "        '''\n",
    "        DDSC step 1\n",
    "        initiualize the matrices A,B with positive values\n",
    "        scale columns of B s.t b(j) = 1\n",
    "        '''\n",
    "        A = np.random.random((self.n,self.m)) # A: n*m\n",
    "        B = np.random.random((self.T,self.n)) # B: T*n\n",
    "\n",
    "        # scale columns s.t. b_i^(j) = 1\n",
    "        B /= sum(B) \n",
    "        \n",
    "        return A, B\n",
    "    \n",
    "    @staticmethod\n",
    "    def _pos_constraint(mat):\n",
    "        '''\n",
    "        nnsc step 2(b)\n",
    "        using only the positive values of matrix  \n",
    "        input: matrix n*m \n",
    "        '''     \n",
    "        indices = np.where(mat < 0.0)\n",
    "        mat[indices] = 0.0\n",
    "        return mat   \n",
    "    \n",
    "    def nnsc(self):\n",
    "        '''\n",
    "        Method as in NNSC from nonnegative sparse coding finland.\n",
    "        from P.Hoyer\n",
    "\n",
    "        return:\n",
    "            A_list, B_list: list of A and B for each appliance i \n",
    "        '''\n",
    "        \n",
    "        acc_nnsc = []\n",
    "        err_nnsc = []\n",
    "        a_nnsc = []\n",
    "        b_nnsc = []\n",
    "        \n",
    "        # used for F\n",
    "        X_train = self.train_set # dict_value \n",
    "        A_list = []\n",
    "        B_list = []\n",
    "        \n",
    "        for X in X_train:\n",
    "            # step 1 \n",
    "            A0, B0 = self._initialization() # initialization \n",
    "            Ap, Bp = A0, B0 \n",
    "            Ap1, Bp1 = Ap, Bp # record previous step Ap, Bp\n",
    "            t = 0\n",
    "            change_A = 1.0\n",
    "            while t <= self.steps and change_A >= self.epsilon:            \n",
    "                Bp = Bp - self.alpha * np.dot((np.dot(Bp, Ap) - X), Ap.T) # step 2a\n",
    "                Bp = self._pos_constraint(Bp) # step 2b \n",
    "                Bp /= sum(Bp) # step 2c \n",
    "                \n",
    "                # step 2d\n",
    "                dot_part2 = np.divide(np.dot(Bp.T, X), (np.dot(np.dot(Bp.T, Bp), Ap) + self.reg_lambda)) # element wise division \n",
    "                Ap = np.multiply(Ap, dot_part2)\n",
    "\n",
    "                change_A = np.linalg.norm(Ap - Ap1)\n",
    "                change_B = np.linalg.norm(Bp - Bp1)\n",
    "                Ap1, Bp1 = Ap, Bp\n",
    "                t += 1\n",
    "                \n",
    "                if t % 10 == 0:\n",
    "                    print(\"iter {t}ï¼šA change = {a:8.4f}\".format(t=t, a=change_A))\n",
    "                \n",
    "            print(\"Gone through one appliance.\\n\")\n",
    "            A_list.append(Ap)\n",
    "            B_list.append(Bp)\n",
    "\n",
    "\n",
    "        # for thesis\n",
    "        acc_iter = self.accuracy(X_train, self.train_sum, B_list, A_list)\n",
    "        err_iter = self.error(X_train, self.train_sum, B_list, A_list)\n",
    "        acc_nnsc.append(acc_iter)\n",
    "        err_nnsc.append(err_iter)\n",
    "        # append norm of matrices\n",
    "        a_nnsc.append(np.linalg.norm(sum(A_list)))\n",
    "        b_nnsc.append(np.linalg.norm(sum(B_list)))\n",
    "\n",
    "        self.acc_nnsc = acc_nnsc\n",
    "        self.err_nnsc = err_nnsc\n",
    "        self.a_nnsc = a_nnsc\n",
    "        self.b_nnsc = b_nnsc\n",
    "        \n",
    "        return A_list, B_list\n",
    "\n",
    "    def accuracy(self, X_train, X_sum, B, A):\n",
    "        '''\n",
    "        inputs:\n",
    "            X_train: dict_value of list \n",
    "        \n",
    "        Everything needs to be in lists of ndarrays\n",
    "        of the components\n",
    "        '''\n",
    "        B_cat = np.hstack(B)\n",
    "        A_cat = np.vstack(A)\n",
    "\n",
    "        A_prime = self.F(X_sum, B_cat, A=A_cat)\n",
    "        A_last = np.split(A_prime, self.k, axis=0)\n",
    "        X_predict = self.predict(A_last, B)\n",
    "        \n",
    "        \n",
    "        X_train = list(X_train)\n",
    "        \n",
    "\n",
    "        acc_numerator = [np.sum(np.minimum((B[i].dot(A_last[i])).sum(axis=0), (sum(X_train[i].sum(axis=0)))))\n",
    "                         for i in range(len(B))]\n",
    "        \n",
    "        \n",
    "        acc_denominator = sum(X_predict).sum()\n",
    "        acc = sum(acc_numerator) / acc_denominator\n",
    "        \n",
    "        acc_denominator = X_sum.sum()\n",
    "        acc_star = sum(acc_numerator) / acc_denominator\n",
    "        return acc, acc_star\n",
    "\n",
    "    def get_accuracy_plot(self):\n",
    "        return self.acc_nnsc, self.acc_ddsc\n",
    "\n",
    "    def get_error_plot(self):\n",
    "        return self.err_nnsc, self.err_ddsc\n",
    "\n",
    "    def get_a(self):\n",
    "        return self.a_nnsc, self.a_ddsc\n",
    "\n",
    "    def get_b(self):\n",
    "        return self.b_nnsc, self.b_ddsc\n",
    "\n",
    "    def error(self,X, X_sum, B, A):\n",
    "        '''\n",
    "        Error for the whole disaggregation part within list, sum the list to get\n",
    "        the resulting disaggregation\n",
    "        Parameters : must have x_train as x\n",
    "        '''\n",
    "        B_cat = np.hstack(B)\n",
    "        A_cat = np.vstack(A)\n",
    "        \n",
    "        \n",
    "        error = [(1.0/2.0) * np.linalg.norm((list(X)[i] - B[i].dot(A[i]))**2) for i in range(self.k)]\n",
    "        error = sum(error)\n",
    "        \n",
    "        A_last_error = self.F(X_sum, B_cat,A_cat)\n",
    "        \n",
    "        A_last_error_list = np.split(A_last_error,self.k,axis=0)\n",
    "        error_star = [(1.0/2.0) * np.linalg.norm((list(X)[i] - B[i].dot(A_last_error_list[i]))**2) for i in range(self.k)]\n",
    "        error_star = sum(error_star)\n",
    "        return error, error_star\n",
    "        \n",
    "    \n",
    "    def F(self, X_sum, B, A):\n",
    "        '''\n",
    "        input is lists of the elements\n",
    "        output list of elements\n",
    "        '''\n",
    "        # 4a  \n",
    "        B = np.asarray(B)\n",
    "        A = np.asarray(A)\n",
    "        \n",
    "        coder = SparseCoder(dictionary=B.T, transform_alpha=self.reg_lambda, transform_algorithm='lasso_cd')    \n",
    "        # B: basis function \n",
    "        # A: activation function   \n",
    "        B_hat, A_hat = librosa.decompose.decompose(X_sum, transformer=coder) \n",
    "        A_hat = self._pos_constraint(A_hat)\n",
    "\n",
    "        return A_hat\n",
    "\n",
    "    def DD(self, B, A):\n",
    "        '''\n",
    "        Taking the parameters as x_train_use and discriminate over the\n",
    "        entire region\n",
    "        '''\n",
    "        # step 3\n",
    "        A_star = np.vstack(A)\n",
    "        B_cat = np.hstack(B)\n",
    "        \n",
    "        # step 4 \n",
    "        change_B = 1 \n",
    "        t = 0\n",
    "        \n",
    "        acc_ddsc = []\n",
    "        err_ddsc = []\n",
    "        a_ddsc = []\n",
    "        b_ddsc = []\n",
    "        \n",
    "        X_sum = self.train_sum # change df to list of list   \n",
    "        X_train = self.train_set\n",
    "        \n",
    "        while t <= self.steps and self.epsilon <= change_B:\n",
    "            B_cat_p = B_cat\n",
    "            \n",
    "            # step 4a\n",
    "            A_hat = self.F(X_sum, B_cat, A_star)\n",
    "            \n",
    "            # step 4b\n",
    "            B_cat = (B_cat - self.alpha * ((X_sum - B_cat.dot(A_hat)).dot(A_hat.T) - (X_sum - B_cat.dot(A_star)).dot(A_star.T)))\n",
    "            \n",
    "            # step 4c\n",
    "            B_cat = self._pos_constraint(B_cat) # scale columns s.t. b_i^(j) = 1\n",
    "            B_cat /= sum(B_cat)\n",
    "            \n",
    "            change_B = np.linalg.norm(B_cat - B_cat_p)\n",
    "            t += 1\n",
    "            \n",
    "    \n",
    "            print(\"step {t}: B change = {c:.4f}\".format(t=t, c=change_B))\n",
    "\n",
    "            # convergence check\n",
    "            A_hat_split = np.split(A_hat, self.k, axis=0)\n",
    "            B_split = np.split(B_cat,self.k,axis=1)\n",
    "            \n",
    "            acc_iter = self.accuracy(X_train, X_sum, B, A_hat_split)\n",
    "            acc_iter = self.accuracy(X_train, X_sum, B_split, A)\n",
    "            err_iter = self.error(X_train, X_sum, B, A_hat_split)\n",
    "\n",
    "#             error, error_star = sc.error(list(x_train.values()),train_sum,B_list,A_list)\n",
    "\n",
    "               \n",
    "            acc_ddsc.append(acc_iter)\n",
    "            err_ddsc.append(err_iter)\n",
    "            a_ddsc.append(np.linalg.norm(A_hat))\n",
    "            b_ddsc.append(np.linalg.norm(B_cat))\n",
    "\n",
    "        self.acc_ddsc = acc_ddsc\n",
    "        self.err_ddsc = err_ddsc\n",
    "        self.a_ddsc = a_ddsc\n",
    "        self.b_ddsc = b_ddsc\n",
    "        return B_cat\n",
    "\n",
    "    def predict(self, A, B):\n",
    "        result = [x.dot(y) for (x, y) in zip(B, A)]\n",
    "        return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localhour</th>\n",
       "      <th>use</th>\n",
       "      <th>air1</th>\n",
       "      <th>furnace1</th>\n",
       "      <th>dishwasher1</th>\n",
       "      <th>regrigerator1</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>1.194</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 01:00:00</td>\n",
       "      <td>1.185</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 02:00:00</td>\n",
       "      <td>1.307</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 03:00:00</td>\n",
       "      <td>1.515</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 04:00:00</td>\n",
       "      <td>1.175</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                localhour    use   air1  furnace1  dishwasher1  regrigerator1  \\\n",
       "house                                                                           \n",
       "2242  2014-01-01 00:00:00  1.194  0.032     0.013          0.0          0.083   \n",
       "2242  2014-01-01 01:00:00  1.185  0.032     0.271          0.0          0.078   \n",
       "2242  2014-01-01 02:00:00  1.307  0.032     0.305          0.0          0.087   \n",
       "2242  2014-01-01 03:00:00  1.515  0.031     0.648          0.0          0.109   \n",
       "2242  2014-01-01 04:00:00  1.175  0.032     0.408          0.0          0.092   \n",
       "\n",
       "       other  \n",
       "house         \n",
       "2242   1.066  \n",
       "2242   0.804  \n",
       "2242   0.883  \n",
       "2242   0.727  \n",
       "2242   0.643  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataprocess import read_data, format_data, split\n",
    "\n",
    "df, houses = read_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = format_data(df, houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-training: \n",
      "iter 10ï¼šA change =   3.9849\n",
      "iter 20ï¼šA change =   0.7306\n",
      "iter 30ï¼šA change =   0.2781\n",
      "iter 40ï¼šA change =   0.1592\n",
      "iter 50ï¼šA change =   0.1039\n",
      "iter 60ï¼šA change =   0.0748\n",
      "iter 70ï¼šA change =   0.0571\n",
      "iter 80ï¼šA change =   0.0452\n",
      "iter 90ï¼šA change =   0.0369\n",
      "iter 100ï¼šA change =   0.0308\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 10ï¼šA change =   4.4623\n",
      "iter 20ï¼šA change =   1.9060\n",
      "iter 30ï¼šA change =   1.2409\n",
      "iter 40ï¼šA change =   0.6273\n",
      "iter 50ï¼šA change =   0.4012\n",
      "iter 60ï¼šA change =   0.4322\n",
      "iter 70ï¼šA change =   0.4267\n",
      "iter 80ï¼šA change =   0.2880\n",
      "iter 90ï¼šA change =   0.1970\n",
      "iter 100ï¼šA change =   0.1555\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 10ï¼šA change =   0.9347\n",
      "iter 20ï¼šA change =   0.9441\n",
      "iter 30ï¼šA change =   0.4859\n",
      "iter 40ï¼šA change =   0.3561\n",
      "iter 50ï¼šA change =   0.2052\n",
      "iter 60ï¼šA change =   0.1539\n",
      "iter 70ï¼šA change =   0.1238\n",
      "iter 80ï¼šA change =   0.0980\n",
      "iter 90ï¼šA change =   0.0778\n",
      "iter 100ï¼šA change =   0.0632\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 10ï¼šA change =   0.3698\n",
      "iter 20ï¼šA change =   0.4029\n",
      "iter 30ï¼šA change =   0.4694\n",
      "iter 40ï¼šA change =   0.5044\n",
      "iter 50ï¼šA change =   0.4050\n",
      "iter 60ï¼šA change =   0.3007\n",
      "iter 70ï¼šA change =   0.2394\n",
      "iter 80ï¼šA change =   0.1998\n",
      "iter 90ï¼šA change =   0.1666\n",
      "iter 100ï¼šA change =   0.1368\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 10ï¼šA change =  12.4633\n",
      "iter 20ï¼šA change =  17.1132\n",
      "iter 30ï¼šA change =  24.1382\n",
      "iter 40ï¼šA change =  26.6982\n",
      "iter 50ï¼šA change =  27.1113\n",
      "iter 60ï¼šA change =  26.7182\n",
      "iter 70ï¼šA change =  26.0889\n",
      "iter 80ï¼šA change =  25.4730\n",
      "iter 90ï¼šA change =  25.0697\n",
      "iter 100ï¼šA change =  24.7181\n",
      "Gone through one appliance.\n",
      "\n",
      "DD: \n",
      "step 1: B change = 1.9525\n",
      "step 2: B change = 1.6921\n",
      "step 3: B change = 1.3109\n",
      "step 4: B change = 1.1395\n",
      "step 5: B change = 1.0880\n"
     ]
    }
   ],
   "source": [
    "timeframe = 336\n",
    "portion = 0.5\n",
    "\n",
    "x_train, x_test = split(d, portion, timeframe)\n",
    "x_train_sum = x_train.pop('use',None) # aggregated \n",
    "x_test_sum = x_test.pop('use',None) \n",
    "x_train_localhour = x_train.pop('localhour',None)\n",
    "x_test_localhour = x_test.pop('localhour',None)\n",
    "\n",
    "k = len(x_train.keys())\n",
    "T, m = x_train[list(x_train.keys())[0]].shape\n",
    "reg_par = 0.0005\n",
    "epsilon = 0.001\n",
    "alpha = 0.001\n",
    "n = 150\n",
    "steps = 100 # steps must be higher than k\n",
    "\n",
    "\n",
    "sc = DDSC(x_train, x_train_sum, alpha, epsilon, reg_par, steps, n, m, T, k)\n",
    "\n",
    "\n",
    "print('pre-training: ')\n",
    "A_list,B_list = sc.nnsc()\n",
    "\n",
    "print('DD: ')\n",
    "# Discriminative Disaggregation training\n",
    "B_cat = sc.DD(B_list, A_list)\n",
    "\n",
    "\n",
    "# Given test examples x_test\n",
    "A_prime = sc.F(x_test_sum.values, B_cat, A=np.vstack(A_list))\n",
    "A_last = np.split(A_prime,k,axis=0)\n",
    "\n",
    "x_predict = sc.predict(A_last,B_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the shape of the first predicted appliances is :%s\" %(np.asarray(x_predict[1]).shape,))\n",
    "x_predict_sum = sum(x_predict)\n",
    "\n",
    "# energy disaggregation accuracy\n",
    "acc = sc.accuracy(x_train.values(), x_train_sum, B_list, A_last)\n",
    "# energy disaggregation error\n",
    "error, error_star = sc.error(x_train.values(), x_train_sum, B_list, A_list)\n",
    "\n",
    "print(\"error: %s, error_star: %s\" % (error, error_star))\n",
    "acc_nnsc, acc_ddsc = sc.get_accuracy_plot()\n",
    "err_nnsc, err_ddsc = sc.get_error_plot()\n",
    "# plotting acc/err\n",
    "a_nnsc, a_ddsc = sc.get_a()\n",
    "b_nnsc, b_ddsc = sc.get_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_nnsc, a_ddsc = sc.get_a()\n",
    "b_nnsc, b_ddsc = sc.get_b()\n",
    "plt.plot(a_ddsc)\n",
    "plt.ylabel('Activations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.title('Activation Norm for DDSC algorithm')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(b_ddsc)\n",
    "plt.ylabel('Basis')\n",
    "plt.xlabel('Iterations')\n",
    "plt.title('Basis Norm for DDSC algorithm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the shape of the first predicted appliances is :%s\" %(np.asarray(list(x_predict)[1]).shape,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_nnddsc, err_ddddsc = sc.get_error_plot()\n",
    "res_err = list(zip(*err_ddddsc)) \n",
    "plt.plot(res_err[0])\n",
    "plt.title('error of DDSC algorithm')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n",
    "\n",
    "acc_nnsc, acc_ddsc = sc.get_accuracy_plot()\n",
    "res_acc = list(zip(*acc_ddsc)) \n",
    "plt.plot(res_acc[0])\n",
    "plt.title('accuracy of DDSC algorithm')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = sc.predict(A_last,B_list)\n",
    "print(\"the shape of the first predicted appliances is :%s\" %(np.asarray(list(x_predict)[0]).shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_predict = sc.predict(A_last,B_list)\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "\n",
    "print(np.asarray(list(x_predict)[0])[0:,house])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.style.use('classic')\n",
    "# row and column sharing\n",
    "house = 6\n",
    "\n",
    "pie_chart_true = []\n",
    "pie_chart_pred = []\n",
    "\n",
    "f, ((ax1, ax2, ax3, ax4, ax5, ax6)) = plt.subplots(6, 1, sharex='col', sharey='row', figsize=(16,12))\n",
    "x = range(x_train[list(x_train.keys())[0]].shape[0])\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "#===========whole home============\n",
    "y_use_true = np.asarray(x_test_sum)[0:,house]\n",
    "ax1.plot(x, y_use_true, color='b',label='Actual energy')\n",
    "y_use_pred = [-1]*x_train[list(x_train.keys())[0]].shape[0]\n",
    "ax1.plot(x, y_use_pred, color='r', label='Predicted')\n",
    "ax1.set_ylim([0,7])\n",
    "ax1.set_ylabel('Whole Home')\n",
    "ax1.legend()\n",
    "\n",
    "#===========regrigerator============\n",
    "y_ref_true = np.asarray(x_test[list(x_test.keys())[0]])[0:,house]\n",
    "ax2.plot(x, y_ref_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_ref_pred = np.asarray(list(x_predict)[0])[0:,house]\n",
    "ax2.plot(x, y_ref_pred, color='r')\n",
    "#ax2.get_yaxis().set_visible(False)\n",
    "ax2.set_ylabel('Refrigerator')\n",
    "\n",
    "\n",
    "\n",
    "#===========dishwasher============\n",
    "y_dish_true = np.asarray(x_test[list(x_test.keys())[1]])[0:,house]\n",
    "ax3.plot(x, y_dish_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_dish_pred = np.asarray(list(x_predict)[1])[0:,house]\n",
    "ax3.plot(x,y_dish_pred, color='r')\n",
    "#ax3.get_yaxis().set_visible(False)\n",
    "ax3.set_ylabel('Dishwasher')\n",
    "#ax3.set_ylim(-0.00001)\n",
    "\n",
    "#===========furnace============\n",
    "y_fur_true = np.asarray(x_test[list(x_test.keys())[2]])[0:,house]\n",
    "ax4.plot(x, y_fur_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_fur_pred = np.asarray(list(x_predict)[2])[0:,house]\n",
    "ax4.plot(x,y_fur_pred, color='r')\n",
    "#ax4.get_yaxis().set_visible(False)\n",
    "ax4.set_ylabel('Furnace')\n",
    "# ax4.set_ylim(-0.05, 0.05)\n",
    "\n",
    "#===========Air============\n",
    "y_air_true = np.asarray(x_test[list(x_test.keys())[3]])[0:,house]\n",
    "ax5.plot(x, y_air_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_air_pred = np.asarray(list(x_predict)[3])[0:,house]\n",
    "ax5.plot(x, y_air_pred, color='r')\n",
    "#ax5.get_yaxis().set_visible(False)\n",
    "ax5.set_ylabel('Air')\n",
    "# ax5.set_xlabel('Hours')\n",
    "\n",
    "#===========others============\n",
    "y_other_true = np.asarray(x_test[list(x_test.keys())[4]])[0:,house]\n",
    "ax6.plot(x, y_other_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_other_pred = np.asarray(list(x_predict)[4])[0:,house]\n",
    "ax6.plot(x, y_other_pred, color='r')\n",
    "#ax5.get_yaxis().set_visible(False)\n",
    "ax6.set_ylabel('Others')\n",
    "ax6.set_xlabel('Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(x_train[list(x_train.keys())[0]].shape[0])\n",
    "y_dish_true = np.asarray(x_test[list(x_test.keys())[1]])[0:,house]\n",
    "y_dish_pred = np.asarray(list(x_predict)[1])[0:,house]\n",
    "\n",
    "result_df = pd.DataFrame({'actuals':y_dish_true, 'predicted':y_dish_pred})\n",
    "result_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_classify_anomalies(df,window):\n",
    "    df['error']=df['actuals']-df['predicted']\n",
    "    df['percentage_change'] = ((df['actuals'] - df['predicted']) / df['actuals']) * 100\n",
    "    df['meanval'] = df['error'].rolling(window=window).mean()\n",
    "    df['deviation'] = df['error'].rolling(window=window).std()\n",
    "    df['-3s'] = df['meanval'] - (2 * df['deviation'])\n",
    "    df['3s'] = df['meanval'] + (2 * df['deviation'])\n",
    "    df['-2s'] = df['meanval'] - (1.75 * df['deviation'])\n",
    "    df['2s'] = df['meanval'] + (1.75 * df['deviation'])\n",
    "    df['-1s'] = df['meanval'] - (1.5 * df['deviation'])\n",
    "    df['1s'] = df['meanval'] + (1.5 * df['deviation'])\n",
    "    cut_list = df[['error', '-3s', '-2s', '-1s', 'meanval', '1s', '2s', '3s']]\n",
    "    cut_values = cut_list.values\n",
    "    cut_sort = np.sort(cut_values)\n",
    "    df['impact'] = [(lambda x: np.where(cut_sort == df['error'][x])[1][0])(x) for x in\n",
    "                               range(len(df['error']))]\n",
    "    severity = {0: 3, 1: 2, 2: 1, 3: 0, 4: 0, 5: 1, 6: 2, 7: 3}\n",
    "    region = {0: \"NEGATIVE\", 1: \"NEGATIVE\", 2: \"NEGATIVE\", 3: \"NEGATIVE\", 4: \"POSITIVE\", 5: \"POSITIVE\", 6: \"POSITIVE\",\n",
    "              7: \"POSITIVE\"}\n",
    "    df['color'] =  df['impact'].map(severity)\n",
    "    df['region'] = df['impact'].map(region)\n",
    "    df['anomaly_points'] = np.where(df['color'] == 3, df['error'], np.nan)\n",
    "    df['load_date'] = pd.date_range(start='6/1/2014', periods=len(df), freq='H')\n",
    "#     df = df.sort_values(by='load_date', ascending=False)\n",
    "#     df.load_date = pd.to_datetime(df['load_date'].astype(str), format=\"%Y-%m-%d\")\n",
    "    return df\n",
    "\n",
    "df = detect_classify_anomalies(result_df, window=5)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_anomaly(df,metric_name):\n",
    "    #error = pd.DataFrame(Order_results.error.values)\n",
    "    #df = df.sort_values(by='load_date', ascending=False)\n",
    "    #df.load_date = pd.to_datetime(df['load_date'].astype(str), format=\"%Y%m%d\")\n",
    "    dates = df.load_date\n",
    "    #meanval = error.rolling(window=window).mean()\n",
    "    #deviation = error.rolling(window=window).std()\n",
    "    #res = error\n",
    "#upper_bond=meanval + (2 * deviation)\n",
    "    #lower_bond=meanval - (2 * deviation)\n",
    "#anomalies = pd.DataFrame(index=res.index, columns=res.columns)\n",
    "    #anomalies[res < lower_bond] = res[res < lower_bond]\n",
    "    #anomalies[res > upper_bond] = res[res > upper_bond]\n",
    "    bool_array = (abs(df['anomaly_points']) > 0)\n",
    "#And a subplot of the Actual Values.\n",
    "    actuals = df[\"actuals\"][-len(bool_array):]\n",
    "    anomaly_points = bool_array * actuals\n",
    "    anomaly_points[anomaly_points == 0] = np.nan\n",
    "#Order_results['meanval']=meanval\n",
    "    #Order_results['deviation']=deviation\n",
    "    color_map= {0: \"palegreen\", 1: \"yellow\", 2: \"orange\", 3: \"red\"}\n",
    "    table = go.Table(\n",
    "    domain=dict(x=[0, 1],\n",
    "                y=[0, 0.3]),\n",
    "    columnwidth=[1, 2 ],\n",
    "    #columnorder=[0, 1, 2,],\n",
    "    header = dict(height = 20,\n",
    "                  values = [['<b>Date</b>'],['<b>Actual Values </b>'],\n",
    "                            ['<b>Predicted</b>'], ['<b>% Difference</b>'],['<b>Severity (0-3)</b>']],\n",
    "                 font = dict(color=['rgb(45, 45, 45)'] * 5, size=14),\n",
    "                  fill = dict(color='#d562be')),\n",
    "    cells = dict(values = [df.round(3)[k].tolist() for k in ['load_date', 'actuals', 'predicted',\n",
    "                                                               'percentage_change','color']],\n",
    "                 line = dict(color='#506784'),\n",
    "                 align = ['center'] * 5,\n",
    "                 font = dict(color=['rgb(40, 40, 40)'] * 5, size=12),\n",
    "                 #format = [None] + [\",.4f\"] + [',.4f'],\n",
    "#suffix=[None] * 4,\n",
    "                 suffix=[None] + [''] + [''] + ['%'] + [''],\n",
    "                 height = 27,\n",
    "                 #fill = dict(color=['rgb(235, 193, 238)', 'rgba(228, 222, 249, 0.65)']))\n",
    "                 fill=dict(color=  # ['rgb(245,245,245)',#unique color for the first column\n",
    "                      [df['color'].map(color_map)],\n",
    "                      )\n",
    "    ))\n",
    "# df['ano'] = np.where(df['color']==3, df['error'], np.nan)\n",
    "    anomalies = go.Scatter(name=\"Anomaly\",\n",
    "                       x=dates,\n",
    "                       xaxis='x1',\n",
    "                       yaxis='y1',\n",
    "                       y=df['anomaly_points'],\n",
    "                       mode='markers',\n",
    "                       marker = dict(color ='red',\n",
    "                      size = 11,line = dict(\n",
    "                                         color = 'red',\n",
    "                                         width = 2)))\n",
    "    upper_bound = go.Scatter(hoverinfo=\"skip\",\n",
    "                         x=dates,\n",
    "                         showlegend =False,\n",
    "                         xaxis='x1',\n",
    "                         yaxis='y1',\n",
    "                         y=df['3s'],\n",
    "                         marker=dict(color=\"#444\"),\n",
    "                         line=dict(\n",
    "                             color=('rgb(23, 96, 167)'),\n",
    "                             width=2,\n",
    "                             dash='dash'),\n",
    "                         fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "                         fill='tonexty')\n",
    "    lower_bound = go.Scatter(name='Confidence Interval',\n",
    "                          x=dates,\n",
    "                         xaxis='x1',\n",
    "                         yaxis='y1',\n",
    "                          y=df['-3s'],\n",
    "                          marker=dict(color=\"#444\"),\n",
    "                          line=dict(\n",
    "                              color=('rgb(23, 96, 167)'),\n",
    "                              width=2,\n",
    "                              dash='dash'),\n",
    "                          fillcolor='rgba(68, 68, 68, 0.3)',\n",
    "                          fill='tonexty')\n",
    "    \n",
    "    Actuals = go.Scatter(name= 'Actuals',\n",
    "                     x= dates,\n",
    "                     y= df['actuals'],\n",
    "                    xaxis='x2', yaxis='y2',\n",
    "                     mode='lines',\n",
    "                     marker=dict(size=12,\n",
    "                                 line=dict(width=1),\n",
    "                                 color='blue'))\n",
    "    \n",
    "    Predicted = go.Scatter(name= 'Predicted',\n",
    "                     x= dates,\n",
    "                     y= df['predicted'],\n",
    "                    xaxis='x2', yaxis='y2',\n",
    "                     mode='lines',\n",
    "                     marker=dict(size=12,\n",
    "                                 line=dict(width=1),\n",
    "                                 color=\"orange\"))\n",
    "# create plot for error...\n",
    "    Error = go.Scatter(name=\"Error\",\n",
    "                   x=dates, y=df['error'],\n",
    "                   xaxis='x1',\n",
    "                   yaxis='y1',\n",
    "                   mode='lines',\n",
    "                   marker=dict(size=12,\n",
    "                               line=dict(width=1),\n",
    "                               color=\"red\"),\n",
    "                   text=\"Error\")\n",
    "    anomalies_map = go.Scatter(name = \"anomaly actual\",\n",
    "                                   showlegend=False,\n",
    "                                   x=dates,\n",
    "                                   y=anomaly_points,\n",
    "                                   mode='markers',\n",
    "                                   xaxis='x2',\n",
    "                                   yaxis='y2',\n",
    "                                    marker = dict(color =\"red\",\n",
    "                                  size = 11,\n",
    "                                 line = dict(\n",
    "                                     color = \"red\",\n",
    "                                     width = 2)))\n",
    "    Mvingavrg = go.Scatter(name=\"Moving Average\",\n",
    "                           x=dates,\n",
    "                           y=df['meanval'],\n",
    "                           mode='lines',\n",
    "                           xaxis='x1',\n",
    "                           yaxis='y1',\n",
    "                           marker=dict(size=12,\n",
    "                                       line=dict(width=1),\n",
    "                                       color=\"green\"),\n",
    "                           text=\"Moving average\")\n",
    "    axis=dict(\n",
    "    showline=True,\n",
    "    zeroline=False,\n",
    "    showgrid=True,\n",
    "    mirror=True,\n",
    "    ticklen=4,\n",
    "    gridcolor='#ffffff',\n",
    "    tickfont=dict(size=10))\n",
    "    \n",
    "    layout1 = dict(\n",
    "    width=1000,\n",
    "    height=865,\n",
    "    autosize=False,\n",
    "    title= metric_name,\n",
    "    margin = dict(t=75),\n",
    "    showlegend=True,\n",
    "    xaxis1=dict(axis, **dict(domain=[0, 1], anchor='y1', showticklabels=True)),\n",
    "    xaxis2=dict(axis, **dict(domain=[0, 1], anchor='y2', showticklabels=True)),\n",
    "    yaxis1=dict(axis, **dict(domain=[2 * 0.21 + 0.20 + 0.09, 1], anchor='x1', hoverformat='.2f')),\n",
    "    yaxis2=dict(axis, **dict(domain=[0.21 + 0.12, 2 * 0.31 + 0.02], anchor='x2', hoverformat='.2f')))\n",
    "    \n",
    "    fig = go.Figure(data = [table,anomalies,anomalies_map,\n",
    "                        upper_bound,lower_bound,Actuals,Predicted,\n",
    "                        Mvingavrg,Error], layout = layout1)\n",
    "    iplot(fig)\n",
    "    pyplot.show()\n",
    "    \n",
    "    \n",
    "classify_df=detect_classify_anomalies(result_df,5)\n",
    "classify_df.reset_index(inplace=True)\n",
    "del classify_df['index']\n",
    "plot_anomaly(classify_df,\"metric_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(\n",
    "    data=[go.Bar(x=[1, 2, 3], y=[1, 3, 2])],\n",
    "    layout=go.Layout(\n",
    "        title=go.layout.Title(text=\"A Bar Chart\")\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade plotly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart_true = [y_ref_true.sum(), y_dish_true.sum(), y_fur_true.sum(), y_air_true.sum(), y_other_true.sum()]\n",
    "pie_chart_pred = [y_ref_pred.sum(), y_dish_pred.sum(), y_fur_pred.sum(), y_air_pred.sum(), y_other_pred.sum()]\n",
    "\n",
    "plt.style.use('classic')\n",
    "\n",
    "def pie_chart(subplot, pie_chart, labels):\n",
    "    # The slices will be ordered and plotted counter-clockwise.\n",
    "    ## --- Plotting the true-piechart\n",
    "    pie_chart_sum = sum(pie_chart)\n",
    "    pie_chart = list(map(lambda x: x/pie_chart_sum,pie_chart))\n",
    "    cmap = plt.cm.prism\n",
    "    colors = cmap(np.linspace(0., 1., len(pie_chart)))\n",
    "    pie_wedge_collection = subplot.pie(pie_chart, colors=colors, labels=labels, labeldistance=1.03)\n",
    "\n",
    "    for pie_wedge in pie_wedge_collection[0]:\n",
    "        pie_wedge.set_edgecolor('white')\n",
    "    # Set aspect ratio to be equal so that pie is drawn as a circle.\n",
    "    \n",
    "    \n",
    "f, ((axes1, axes2)) = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(16,16))\n",
    "\n",
    "labels = x_test.keys()\n",
    "print(labels)\n",
    "pie_chart(axes1,pie_chart_true,labels)\n",
    "axes1.set_title('True usage')\n",
    "pie_chart(axes2,pie_chart_pred,labels)\n",
    "axes2.set_title('Predicted usage')\n",
    "# axes2.text(0.95, 0.01, 'Accuracy of ' + str(round(sc.acc[0],1)), verticalalignment='center', horizontalalignment='right', transform=axes2.transAxes, color='black', fontsize=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the B matrices (basis functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "# row and column sharing\n",
    "f, ((ax1, ax2, ax3)) = plt.subplots(3, 1, sharex='col', sharey='row', figsize=(16,12))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "B_list[0] = B_list[0]/np.sum(B_list[0],axis=1)[:,None]  # Normalize\n",
    "ax1.pcolor(B_list[0], cmap = cm.Greys_r)\n",
    "B_list[1] = B_list[1]/np.sum(B_list[1],axis=1)[:,None]  # Normalize\n",
    "ax2.pcolor(B_list[1], cmap = cm.Greys_r)\n",
    "B_list[2] = B_list[2]/np.sum(B_list[2],axis=1)[:,None]  # Normalize\n",
    "ax3.pcolor(B_list[2], cmap = cm.Greys_r)\n",
    "\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax2.get_xaxis().set_visible(False)\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "ax3.get_xaxis().set_visible(False)\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "\n",
    "# plt.savefig(figure_directory+'basis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "# row and column sharing\n",
    "f, ((ax1, ax2, ax3)) = plt.subplots(3, 1, sharex='col', sharey='row', figsize=(16,12))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "for base in range(7):\n",
    "    ax1.plot(range(n),B_list[0][base,0:])\n",
    "    ax2.plot(range(n),B_list[1][base,0:])\n",
    "    ax3.plot(range(n),B_list[2][base,0:])\n",
    "\n",
    "ax1.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "ax1.set_ylim([0,0.04])\n",
    "ax1.set_ylabel('Refrigerator')\n",
    "ax2.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "ax2.set_ylim([0,0.06])\n",
    "ax2.set_ylabel('Dishwasher')\n",
    "ax3.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "ax3.set_ylim([0,0.02])\n",
    "ax3.set_ylabel('Furnace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
