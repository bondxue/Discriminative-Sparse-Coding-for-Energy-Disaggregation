{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminative Sparse Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import librosa\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import SparseCoder,DictionaryLearning\n",
    "from sklearn import cluster\n",
    "# from lightning.regression import CDRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDSC():\n",
    "    def __init__(self, train_set, train_sum, alpha, \n",
    "                 epsilon, reg_lambda, steps, n, m, T, k):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            train_set: X_i matrix with dim T*m for each individual appliance \n",
    "            train_sum: X_sum aggregated matrix T*m \n",
    "            alpha: gradiant rate for the convergence step for DD (4b).\n",
    "            epsilon: gradient stepsize of the pre-training (2e) ||A_t+1 - A_t||< epsilon \n",
    "            reg_lambda: reguarization weight of penalty function\n",
    "            steps: interations to be performed for the convergence part\n",
    "            n: number of basis functions \n",
    "            m: number of features (households)\n",
    "            T: number of samples (hours)\n",
    "            k: number of applicances i (1, k)\n",
    "        \"\"\"\n",
    "        self.train_set = train_set\n",
    "        self.train_sum = train_sum\n",
    "        self.alpha = alpha \n",
    "        self.epsilon = epsilon\n",
    "        self.reg_lambda = reg_lambda\n",
    "        self.steps = steps\n",
    "        self.n = n \n",
    "        self.m = m\n",
    "        self.T = T\n",
    "        self.k = k\n",
    "        \n",
    "        # ======= Instances that can be used for plotting =====\n",
    "        self.acc_nnsc = None\n",
    "        self.err_nnsc = None\n",
    "        self.acc_ddsc = None\n",
    "        self.err_ddsc = None\n",
    "        self.a_nnsc = None\n",
    "        self.b_nnsc = None\n",
    "        self.a_ddsc = None\n",
    "        self.b_ddsc = None\n",
    "\n",
    "    def _initialization(self):\n",
    "        '''\n",
    "        DDSC step 1\n",
    "        initiualize the matrices A,B with positive values\n",
    "        scale columns of B s.t b(j) = 1\n",
    "        '''\n",
    "        A = np.random.random((self.n,self.m)) # A: n*m\n",
    "        B = np.random.random((self.T,self.n)) # B: T*n\n",
    "\n",
    "        # scale columns s.t. b_i^(j) = 1\n",
    "        B /= sum(B) \n",
    "        \n",
    "        return A, B\n",
    "    \n",
    "    @staticmethod\n",
    "    def _pos_constraint(mat):\n",
    "        '''\n",
    "        nnsc step 2(b)\n",
    "        using only the positive values of matrix  \n",
    "        input: matrix n*m \n",
    "        '''     \n",
    "        indices = np.where(mat < 0.0)\n",
    "        mat[indices] = 0.0\n",
    "        return mat   \n",
    "    \n",
    "    def nnsc(self, X_dic):\n",
    "        '''\n",
    "        Method as in NNSC from nonnegative sparse coding finland.\n",
    "        from P.Hoyer\n",
    "        X_dic: dict of X_i for all appliances\n",
    "        '''\n",
    "        \n",
    "        acc_nnsc = []\n",
    "        err_nnsc = []\n",
    "        a_nnsc = []\n",
    "        b_nnsc = []\n",
    "        # used for F\n",
    "        X_train = self.train_set.values()\n",
    "        A_list = []\n",
    "        B_list = []\n",
    "        for X in X_dic:\n",
    "            # step 1 \n",
    "            A0, B0 = self._initialization() # initialization \n",
    "            Ap, Bp = A0, B0 \n",
    "            Ap1, Bp1 = Ap, Bp # record previous step Ap, Bp\n",
    "            t = 0\n",
    "            change_A = 1.0\n",
    "            while t <= self.steps and change_A >= self.epsilon:            \n",
    "                Bp = Bp - self.alpha * np.dot((np.dot(Bp, Ap) - X), Ap.T) # step 2a\n",
    "                Bp = self._pos_constraint(Bp) # step 2b \n",
    "                Bp /= sum(Bp) # step 2c \n",
    "                \n",
    "                # step 2d\n",
    "                dot_part2 = np.divide(np.dot(Bp.T,X),(np.dot(np.dot(Bp.T,Bp),Ap) + self.reg_lambda)) # element wise division \n",
    "                Ap = np.multiply(Ap,dot_part2)\n",
    "\n",
    "                change_A = np.linalg.norm(Ap - Ap1)\n",
    "                change_B = np.linalg.norm(Bp - Bp1)\n",
    "                Ap1, Bp1 = Ap, Bp\n",
    "                t += 1\n",
    "                \n",
    "                print(\"iter {t}ï¼šA change = {a:8.4f}\".format(t=t, a=change_A))\n",
    "                \n",
    "            print(\"Gone through one appliance.\\n\")\n",
    "            A_list.append(Ap)\n",
    "            B_list.append(Bp)\n",
    "\n",
    "\n",
    "        # for thesis\n",
    "        acc_iter = self.accuracy(X_train,self.train_sum,B_list,A_list)\n",
    "        err_iter = self.error(X_train,self.train_sum,B_list,A_list)\n",
    "        acc_nnsc.append(acc_iter)\n",
    "        err_nnsc.append(err_iter)\n",
    "        # append norm of matrices\n",
    "        a_nnsc.append(np.linalg.norm(sum(A_list)))\n",
    "        b_nnsc.append(np.linalg.norm(sum(B_list)))\n",
    "\n",
    "        self.acc_nnsc = acc_nnsc\n",
    "        self.err_nnsc = err_nnsc\n",
    "        self.a_nnsc = a_nnsc\n",
    "        self.b_nnsc = b_nnsc\n",
    "        return A_list,B_list\n",
    "\n",
    "    def accuracy(self,X,X_sum,B,A):\n",
    "        '''\n",
    "        Everything needs to be in lists of ndarrays\n",
    "        of the components\n",
    "        '''\n",
    "        B_cat = np.hstack(B)\n",
    "        A_cat = np.vstack(A)\n",
    "\n",
    "        A_prime = self.F(X_sum.values,B_cat,A=A_cat)\n",
    "        A_last = np.split(A_prime,self.k,axis=0)\n",
    "        X_predict = self.predict(A_last,B)\n",
    "        acc_numerator = (map(lambda i: (np.minimum( (B[i].dot(A_last[i])).sum(), \n",
    "                        (sum(list(X)[i].sum())))),\n",
    "                        range(len(B))))\n",
    "        acc_denominator = sum(X_predict).sum()\n",
    "        acc = sum(acc_numerator) / acc_denominator\n",
    "        \n",
    "        acc_numerator = (map(lambda i: (np.minimum( (B[i].dot(A_last[i])).sum() ,\n",
    "                        (sum(list(X)[i].sum())))) ,\n",
    "                        range(len(B))))\n",
    "        acc_denominator = X_sum.values.sum()\n",
    "        acc_star = sum(acc_numerator) / acc_denominator\n",
    "        return acc, acc_star\n",
    "\n",
    "    def get_accuracy_plot(self):\n",
    "        return self.acc_nnsc, self.acc_ddsc\n",
    "\n",
    "    def get_error_plot(self):\n",
    "        return self.err_nnsc, self.err_ddsc\n",
    "\n",
    "    def get_a(self):\n",
    "        return self.a_nnsc, self.a_ddsc\n",
    "\n",
    "    def get_b(self):\n",
    "        return self.b_nnsc, self.b_ddsc\n",
    "\n",
    "    def error(self,x,x_sum,B,A):\n",
    "        '''\n",
    "        Error for the whole disaggregation part within list, sum the list to get\n",
    "        the resulting disaggregation\n",
    "        Parameters : must have x_train as x\n",
    "        '''\n",
    "        B_cat = np.hstack(B)\n",
    "        A_cat = np.vstack(A)\n",
    "        \n",
    "        error = (map(lambda i: ((1.0/2.0)*np.linalg.norm( (list(x)[i] - B[i].dot(A[i]))**2)), range(len(B))))\n",
    "        error = sum(error)\n",
    "        \n",
    "        A_last_error = self.F(x_sum.values,B_cat,A_cat)\n",
    "        A_last_error_list = np.split(A_last_error,self.k,axis=0)\n",
    "        error_star = (map(lambda i: ((1.0/2.0)*np.linalg.norm((list(x)[i] - B[i].dot(A_last_error_list[i]))**2)),range(len(B))))\n",
    "        error_star = sum(error_star)\n",
    "        return error, error_star\n",
    "\n",
    "    def pre_training(self,X_dict):\n",
    "        # TODO : implement s.t. conditions and frobenius norm to the options\n",
    "        tic = time.time()\n",
    "        #the NON NEGATIVE SPARSE CODING\n",
    "        A_list,B_list = self.nnsc(X_dict)\n",
    "\n",
    "        tac = time.time()\n",
    "        t = tac - tic\n",
    "        print('time of computations for Dictionary Learning with m = {m} and T = {T} took: {t:.3f}s'.format(m=self.m,T=self.T,t=t))\n",
    "        return A_list,B_list\n",
    "        \n",
    "    \n",
    "    def F(self, X_sum, B, A):\n",
    "        '''\n",
    "        input is lists of the elements\n",
    "        output list of elements\n",
    "        '''\n",
    "        # 4a  \n",
    "        B = np.asarray(B)\n",
    "        A = np.asarray(A)\n",
    "        \n",
    "        coder = SparseCoder(dictionary=B.T,\n",
    "                            transform_alpha=self.reg_lambda, transform_algorithm='lasso_cd')    \n",
    "        # B: basis function \n",
    "        # A: activation function   \n",
    "        B_hat, A_hat = librosa.decompose.decompose(X_sum,transformer=coder) \n",
    "        A_hat = self._pos_constraint(A_hat)\n",
    "\n",
    "        return A_hat\n",
    "\n",
    "    def DD(self, X_sum, B, A):\n",
    "        '''\n",
    "        Taking the parameters as x_train_use and discriminate over the\n",
    "        entire region\n",
    "        '''\n",
    "        # step 3\n",
    "        A_star = np.vstack(A)\n",
    "        B_cat = np.hstack(B)\n",
    "        \n",
    "        # step 4 \n",
    "        change_B = 1 \n",
    "        t = 0\n",
    "        \n",
    "        acc_ddsc = []\n",
    "        err_ddsc = []\n",
    "        a_ddsc = []\n",
    "        b_ddsc = []\n",
    "        \n",
    "        X = self.train_set.values()\n",
    "        \n",
    "        while t <= self.steps and self.epsilon <= change_B:\n",
    "            B_cat_p = B_cat\n",
    "            # step 4a\n",
    "            A_hat = self.F(X_sum, B_cat, A_star)\n",
    "            # step 4b\n",
    "            B_cat = (B_cat - self.alpha * ((X_sum - B_cat.dot(A_hat)).dot(A_hat.T) - (X_sum - B_cat.dot(A_star)).dot(A_star.T)))\n",
    "            # step 4c\n",
    "            B_cat = self._pos_constraint(B_cat) # scale columns s.t. b_i^(j) = 1\n",
    "            B_cat /= sum(B_cat)\n",
    "            \n",
    "            change_B = np.linalg.norm(B_cat - B_cat_p)\n",
    "            t += 1\n",
    "            print(\"step {t}: DD change = {c:.4f}\".format(t=t, c=change_B))\n",
    "\n",
    "            # convergence check\n",
    "            A_hat_split = np.split(A_hat, self.k, axis=0)\n",
    "            B_split = np.split(B_cat,self.k,axis=1)\n",
    "            acc_iter = self.accuracy(X, self.train_sum, B, A_hat_split)\n",
    "            acc_iter = self.accuracy(X, self.train_sum, B_split, A)\n",
    "            err_iter = self.error(X, self.train_sum, B, A_hat_split)\n",
    "            print(list(acc_iter))\n",
    "#             error, error_star = sc.error(list(x_train.values()),train_sum,B_list,A_list)\n",
    "            print(list(err_iter))\n",
    "               \n",
    "            acc_ddsc.append(acc_iter)\n",
    "            err_ddsc.append(err_iter)\n",
    "            a_ddsc.append(np.linalg.norm(A_hat))\n",
    "            b_ddsc.append(np.linalg.norm(B_cat))\n",
    "\n",
    "            \n",
    "\n",
    "        self.acc_ddsc = acc_ddsc\n",
    "        self.err_ddsc = err_ddsc\n",
    "        self.a_ddsc = a_ddsc\n",
    "        self.b_ddsc = b_ddsc\n",
    "        return B_cat\n",
    "\n",
    "    def predict(self,A,B):\n",
    "        x = map(lambda x,y: x.dot(y),B,A)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localhour</th>\n",
       "      <th>use</th>\n",
       "      <th>air1</th>\n",
       "      <th>furnace1</th>\n",
       "      <th>dishwasher1</th>\n",
       "      <th>regrigerator1</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>1.194</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 01:00:00</td>\n",
       "      <td>1.185</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 02:00:00</td>\n",
       "      <td>1.307</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 03:00:00</td>\n",
       "      <td>1.515</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>2014-01-01 04:00:00</td>\n",
       "      <td>1.175</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                localhour    use   air1  furnace1  dishwasher1  regrigerator1  \\\n",
       "house                                                                           \n",
       "2242  2014-01-01 00:00:00  1.194  0.032     0.013          0.0          0.083   \n",
       "2242  2014-01-01 01:00:00  1.185  0.032     0.271          0.0          0.078   \n",
       "2242  2014-01-01 02:00:00  1.307  0.032     0.305          0.0          0.087   \n",
       "2242  2014-01-01 03:00:00  1.515  0.031     0.648          0.0          0.109   \n",
       "2242  2014-01-01 04:00:00  1.175  0.032     0.408          0.0          0.092   \n",
       "\n",
       "       other  \n",
       "house         \n",
       "2242   1.066  \n",
       "2242   0.804  \n",
       "2242   0.883  \n",
       "2242   0.727  \n",
       "2242   0.643  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataprocess import read_data, format_data, split\n",
    "\n",
    "df, houses = read_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = format_data(df, houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2242     94   2034   2829   2974    135   2156    508   3273    898  ...  \\\n",
      "0   1.194  1.561  0.713  0.397  2.536  1.043  2.947  0.108  1.800  0.410  ...   \n",
      "1   1.185  1.421  0.658  0.381  1.795  0.158  1.460  0.102  5.010  0.488  ...   \n",
      "2   1.307  1.434  1.641  0.300  1.305  1.097  1.353  0.101  2.939  0.531  ...   \n",
      "3   1.515  1.283  1.397  0.262  0.368  0.715  1.836  0.101  0.080  0.222  ...   \n",
      "4   1.175  1.147  0.444  0.225  0.655  0.111  1.345  5.169  0.091  0.222  ...   \n",
      "5   1.132  0.244  0.377  0.189  0.403  0.712  1.570  2.633  0.132  0.193  ...   \n",
      "6   0.946  0.207  0.369  0.321  1.243  0.687  1.604  1.711  0.237  0.116  ...   \n",
      "7   1.240  0.195  0.696  0.193  0.400  0.139  0.329  1.095  0.132  0.051  ...   \n",
      "8   1.140  0.261  0.341  0.173  0.514  1.083  0.338  0.103  0.329  0.220  ...   \n",
      "9   1.841  0.286  0.129  0.297  1.831  0.104  0.177  1.290  0.246  0.250  ...   \n",
      "10  1.226  0.209  0.501  0.174  3.284  1.184  0.210  0.112  1.239  0.089  ...   \n",
      "11  2.165  0.368  0.198  0.174  0.572  0.229  0.345  0.152  0.564  0.640  ...   \n",
      "12  1.468  0.204  0.643  0.173  0.686  0.225  0.176  3.283  1.265  2.059  ...   \n",
      "13  1.857  0.300  1.295  0.176  3.299  0.176  0.232  0.325  0.908  0.346  ...   \n",
      "14  2.897  0.200  1.037  0.225  0.583  0.244  0.468  0.348  0.204  0.057  ...   \n",
      "15  3.787  0.443  0.772  0.314  0.445  0.075  0.343  0.449  0.891  0.100  ...   \n",
      "16  1.035  2.097  0.957  0.315  0.834  0.068  0.783  0.355  0.114  0.187  ...   \n",
      "17  1.671  0.591  0.138  0.285  0.670  0.127  0.390  0.485  0.202  0.141  ...   \n",
      "18  1.925  0.379  0.489  0.315  0.405  0.086  0.716  0.488  0.215  0.231  ...   \n",
      "19  4.453  0.754  1.796  0.310  2.114  0.144  1.108  0.641  0.197  0.388  ...   \n",
      "20  4.341  0.368  1.629  0.343  2.299  0.261  1.692  0.153  0.198  0.190  ...   \n",
      "21  4.006  1.657  1.538  0.337  2.052  0.302  5.640  0.148  0.946  0.360  ...   \n",
      "22  3.831  0.291  1.661  0.220  1.615  0.892  2.785  0.146  0.195  0.847  ...   \n",
      "23  4.320  0.388  1.523  0.189  2.356  0.335  0.487  0.146  0.230  0.199  ...   \n",
      "\n",
      "     3687   3678   3443   3721   3873   2004   3938   2171   2710   2845  \n",
      "0   1.107  1.167  0.135  0.511  0.163  0.555  0.177  2.177  6.749  1.160  \n",
      "1   1.717  0.521  0.096  0.636  0.268  0.504  0.082  1.058  2.181  1.087  \n",
      "2   1.010  0.649  1.300  1.736  0.163  0.503  0.082  0.343  1.345  0.951  \n",
      "3   0.987  0.133  0.086  0.155  0.154  0.460  0.187  1.398  3.884  0.481  \n",
      "4   0.634  0.217  0.134  0.053  0.051  0.535  0.083  0.420  2.015  0.450  \n",
      "5   0.298  0.112  2.204  0.074  0.334  0.525  0.209  0.276  0.504  0.345  \n",
      "6   0.444  0.180  0.134  0.092  0.058  0.405  0.232  0.563  1.898  0.353  \n",
      "7   0.288  0.382  0.283  0.340  0.058  0.540  0.299  0.159  4.033  0.666  \n",
      "8   0.353  0.114  0.349  0.159  0.146  0.662  0.277  0.160  6.443  0.332  \n",
      "9   0.442  1.676  0.294  0.699  0.814  0.476  0.287  0.160  2.682  0.726  \n",
      "10  0.463  1.581  0.266  0.224  0.195  0.454  0.108  2.314  0.885  0.406  \n",
      "11  0.842  0.111  1.442  0.141  0.105  0.471  0.143  1.366  0.695  0.422  \n",
      "12  0.286  0.518  0.313  0.219  0.210  0.574  0.082  2.262  0.826  0.578  \n",
      "13  0.703  0.345  0.447  0.394  0.106  0.583  0.083  4.804  0.717  0.578  \n",
      "14  0.318  1.274  0.255  1.583  0.654  0.455  0.082  2.245  0.833  0.811  \n",
      "15  0.518  0.299  5.923  0.310  2.394  0.433  0.179  0.971  0.901  0.552  \n",
      "16  0.530  0.459  0.483  0.164  0.543  0.483  0.126  4.570  2.232  0.394  \n",
      "17  0.189  0.368  0.330  0.049  0.156  0.501  0.082  0.310  0.960  0.280  \n",
      "18  0.179  1.394  0.284  1.265  0.589  0.409  0.207  0.408  1.233  0.706  \n",
      "19  0.626  0.927  0.421  1.877  0.684  0.606  1.050  0.923  1.779  1.617  \n",
      "20  0.774  1.016  0.397  0.268  0.548  0.472  0.769  0.667  1.554  5.643  \n",
      "21  0.851  0.511  0.341  0.176  0.743  0.550  0.504  0.645  6.403  1.182  \n",
      "22  0.986  0.341  0.371  0.193  0.309  0.344  1.722  3.534  6.814  1.732  \n",
      "23  1.093  0.802  0.216  1.629  0.337  0.515  0.881  1.669  0.713  2.743  \n",
      "\n",
      "[24 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "factor_n_t = 5 # heuristically determined\n",
    "\n",
    "timeframes = [14,30,60]\n",
    "timeframes = [48]\n",
    "# timeframes = [336] # 24*7*2\n",
    "#timeframes = [x*24 for x in timeframes]\n",
    "alphas = [0.0001]\n",
    "#alphas = [0.0001, 0.00001, 0.000001]\n",
    "portion = 0.5\n",
    "# Good values (t,n,alpha)\n",
    "# (14,40, alpha = 0.0001)\n",
    "# (336,800, alpha = 0.00001)\n",
    "# (720,,1400, alpha = )\n",
    "for timeframe, alpha in zip(timeframes,alphas):\n",
    "#     n = int(factor_n_t*timeframe)\n",
    "    n = 250 # number of basis function \n",
    "    x_train, x_test = split(d,portion,timeframe)\n",
    "# use in whole house disaggregation step\n",
    "    x_train_use = x_train.pop('use',None)\n",
    "    x_test_use = x_test.pop('use',None)\n",
    "    x_train_localhour = x_train.pop('localhour',None)\n",
    "    x_test_localhour = x_test.pop('localhour',None)\n",
    "    train_sum = sum(x_train.values())\n",
    "# algorithm starts\n",
    "\n",
    "\n",
    "print(train_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============started the pre-training============\n",
      "iter 1ï¼šA change =  41.0364\n",
      "iter 2ï¼šA change =   0.3077\n",
      "iter 3ï¼šA change =   0.3659\n",
      "iter 4ï¼šA change =   0.4519\n",
      "iter 5ï¼šA change =   0.5561\n",
      "iter 6ï¼šA change =   0.6586\n",
      "iter 7ï¼šA change =   0.7361\n",
      "iter 8ï¼šA change =   0.7723\n",
      "iter 9ï¼šA change =   0.7647\n",
      "iter 10ï¼šA change =   0.7232\n",
      "iter 11ï¼šA change =   0.6626\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 1ï¼šA change =  40.6844\n",
      "iter 2ï¼šA change =   0.5236\n",
      "iter 3ï¼šA change =   0.5506\n",
      "iter 4ï¼šA change =   0.5713\n",
      "iter 5ï¼šA change =   0.5839\n",
      "iter 6ï¼šA change =   0.5890\n",
      "iter 7ï¼šA change =   0.5889\n",
      "iter 8ï¼šA change =   0.5855\n",
      "iter 9ï¼šA change =   0.5805\n",
      "iter 10ï¼šA change =   0.5748\n",
      "iter 11ï¼šA change =   0.5689\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 1ï¼šA change =  42.0758\n",
      "iter 2ï¼šA change =   0.1015\n",
      "iter 3ï¼šA change =   0.1079\n",
      "iter 4ï¼šA change =   0.1216\n",
      "iter 5ï¼šA change =   0.1368\n",
      "iter 6ï¼šA change =   0.1491\n",
      "iter 7ï¼šA change =   0.1559\n",
      "iter 8ï¼šA change =   0.1565\n",
      "iter 9ï¼šA change =   0.1516\n",
      "iter 10ï¼šA change =   0.1426\n",
      "iter 11ï¼šA change =   0.1314\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 1ï¼šA change =  41.1946\n",
      "iter 2ï¼šA change =   0.0627\n",
      "iter 3ï¼šA change =   0.0647\n",
      "iter 4ï¼šA change =   0.0671\n",
      "iter 5ï¼šA change =   0.0702\n",
      "iter 6ï¼šA change =   0.0738\n",
      "iter 7ï¼šA change =   0.0776\n",
      "iter 8ï¼šA change =   0.0813\n",
      "iter 9ï¼šA change =   0.0846\n",
      "iter 10ï¼šA change =   0.0872\n",
      "iter 11ï¼šA change =   0.0890\n",
      "Gone through one appliance.\n",
      "\n",
      "iter 1ï¼šA change =  37.3439\n",
      "iter 2ï¼šA change =   0.8778\n",
      "iter 3ï¼šA change =   0.9086\n",
      "iter 4ï¼šA change =   0.9499\n",
      "iter 5ï¼šA change =   0.9976\n",
      "iter 6ï¼šA change =   1.0485\n",
      "iter 7ï¼šA change =   1.1010\n",
      "iter 8ï¼šA change =   1.1540\n",
      "iter 9ï¼šA change =   1.2071\n",
      "iter 10ï¼šA change =   1.2599\n",
      "iter 11ï¼šA change =   1.3123\n",
      "Gone through one appliance.\n",
      "\n",
      "time of computations for Dictionary Learning with m = 21 and T = 24 took: 4.621s\n",
      "=============done pre_training==============\n",
      "[0.16582896872822744, 0.40579408793391847]\n",
      "[152.47382661347777, 152.47382661315314]\n",
      "step 1: DD change = 0.0826\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-319d80b891e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=============done pre_training==============\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Discriminative Disaggregation training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mB_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_use\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=================done DD==============\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Given test examples x_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d10a5a13ef95>\u001b[0m in \u001b[0;36mDD\u001b[0;34m(self, X_sum, B, A)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0macc_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0macc_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0merr_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macts_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;31m#             error, error_star = sc.error(list(x_train.values()),train_sum,B_list,A_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d10a5a13ef95>\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, x, x_sum, B, A)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mA_last_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB_cat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mA_last_error_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_last_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0merror_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_last_error_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-d10a5a13ef95>\u001b[0m in \u001b[0;36mF\u001b[0;34m(self, X_sum, B, A)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# B: basis function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# A: activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mB_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mA_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/librosa/decompose.py\u001b[0m in \u001b[0;36mdecompose\u001b[0;34m(S, n_components, transformer, sort, fit, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mn_nonzero_coefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_n_nonzero_coefs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_max_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m             n_jobs=self.n_jobs, positive=self.positive_code)\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_sign\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36msparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    316\u001b[0m                               \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                               positive=positive)\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36m_sparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, regularization, copy_cov, init, max_iter, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mnew_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, check_input)\u001b[0m\n\u001b[1;32m    749\u001b[0m                           \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                           \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                           check_input=False)\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mdual_gaps_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/python36/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    470\u001b[0m             model = cd_fast.enet_coordinate_descent_gram(\n\u001b[1;32m    471\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m                 tol, rng, random, positive)\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mprecompute\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             model = cd_fast.enet_coordinate_descent(\n",
      "\u001b[0;32msklearn/linear_model/_cd_fast.pyx\u001b[0m in \u001b[0;36msklearn.linear_model._cd_fast.enet_coordinate_descent_gram\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "factor_n_t = 5 # heuristically determined\n",
    "\n",
    "timeframes = [14,30,60]\n",
    "timeframes = [48]\n",
    "# timeframes = [336] # 24*7*2\n",
    "#timeframes = [x*24 for x in timeframes]\n",
    "alphas = [0.0001]\n",
    "#alphas = [0.0001, 0.00001, 0.000001]\n",
    "portion = 0.5\n",
    "# Good values (t,n,alpha)\n",
    "# (14,40, alpha = 0.0001)\n",
    "# (336,800, alpha = 0.00001)\n",
    "# (720,,1400, alpha = )\n",
    "for timeframe, alpha in zip(timeframes,alphas):\n",
    "#     n = int(factor_n_t*timeframe)\n",
    "    n = 250 # number of basis function \n",
    "    x_train, x_test = split(d,portion,timeframe)\n",
    "# use in whole house disaggregation step\n",
    "    x_train_use = x_train.pop('use',None)\n",
    "    x_test_use = x_test.pop('use',None)\n",
    "    x_train_localhour = x_train.pop('localhour',None)\n",
    "    x_test_localhour = x_test.pop('localhour',None)\n",
    "# algorithm starts\n",
    "\n",
    "    # parameters\n",
    "    train_set = x_train\n",
    "    test_set = x_test\n",
    "    train_sum = sum(x_train.values())\n",
    "    k = len(x_train.keys())\n",
    "    T,m = x_train[list(x_train.keys())[0]].shape\n",
    "    rp = 0.0005\n",
    "    epsilon = 0.001\n",
    "    alpha = 0.0001\n",
    "    steps = 10# steps must be higher than k\n",
    "    # get data\n",
    "    \n",
    "\n",
    "    # Sparse Coding pre_training\n",
    "    sc = DDSC(train_set,train_sum,alpha,epsilon,rp,steps,n,m,T,k)\n",
    "    print(\"============started the pre-training============\")\n",
    "    A_list,B_list = sc.pre_training(x_train.values())\n",
    "    print(\"=============done pre_training==============\")\n",
    "    # Discriminative Disaggregation training\n",
    "    B_cat = sc.DD(x_train_use.values,B_list,A_list)\n",
    "    print(\"=================done DD==============\")\n",
    "    # Given test examples x_test\n",
    "    A_prime = sc.F(x_test_use.values,B_cat,A=np.vstack(A_list))\n",
    "    A_last = np.split(A_prime,k,axis=0)\n",
    "    x_predict = sc.predict(A_last,B_list)\n",
    "    print(\"the shape of the first predicted appliances is :%s\" %(np.asarray(list(x_predict)[0]).shape,))\n",
    "    x_predict_sum = sum(x_predict)\n",
    "    \n",
    "    # energy disaggregation accuracy\n",
    "    acc = sc.accuracy(x_train.values(),train_sum,B_list,A_last)\n",
    "    # energy disaggregation error\n",
    "    error, error_star = sc.error(x_train.values(),train_sum,B_list,A_list)\n",
    "    print(\"error: %s, error_star: %s\" % (error, error_star))\n",
    "    acc_nnsc, acc_ddsc = sc.get_accuracy_plot()\n",
    "    err_nnsc, err_ddsc = sc.get_error_plot()\n",
    "    # plotting acc/err\n",
    "    a_nnsc, a_ddsc = sc.get_a()\n",
    "    b_nnsc, b_ddsc = sc.get_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_nnddsc, acc_ddddsc = sc.get_accuracy_plot()\n",
    "# for acc in acc_ddddsc:\n",
    "#     print(acc[1])\n",
    "# res = list(zip(*acc_ddddsc)) \n",
    "# plt.plot(res[1])\n",
    "err_nnddsc, err_ddddsc = sc.get_error_plot()\n",
    "res_err = list(zip(*err_ddddsc)) \n",
    "plt.plot(res_err[0])\n",
    "plt.show()\n",
    "\n",
    "acc_nnsc, acc_ddsc = sc.get_accuracy_plot()\n",
    "res_acc = list(zip(*acc_ddsc)) \n",
    "plt.plot(res_acc[0])\n",
    "plt.show()\n",
    "# err_nnddsc, err_ddddsc = sc.get_error_plot()\n",
    "\n",
    "\n",
    "# # plotting acc/err\n",
    "# # a_nnsc, a_ddsc = sc.get_a()\n",
    "# # b_nnsc, b_ddsc = sc.get_b()\n",
    "# # error, error_star = sc.error(list(x_train.values()),train_sum,B_list,A_list)\n",
    "# # print(\"error: %s, error_star: %s\" % (sum(error),sum(error_star)))\n",
    "\n",
    "# for error, error_star in err_ddddsc:\n",
    "#     print(sum(error.value()))\n",
    "# # print(err_ddddsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = sc.predict(A_last,B_list)\n",
    "print(\"the shape of the first predicted appliances is :%s\" %(np.asarray(list(x_predict)[0]).shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_predict = sc.predict(A_last,B_list)\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "\n",
    "print(np.asarray(list(x_predict)[0])[0:,house])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-poster')\n",
    "plt.style.use('classic')\n",
    "# row and column sharing\n",
    "house = 10\n",
    "\n",
    "pie_chart_true = []\n",
    "pie_chart_pred = []\n",
    "\n",
    "f, ((ax1, ax2, ax3, ax4, ax5, ax6)) = plt.subplots(6, 1, sharex='col', sharey='row', figsize=(16,12))\n",
    "x = range(x_train[list(x_train.keys())[0]].shape[0])\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "#===========whole home============\n",
    "y_use_true = np.asarray(x_test_use)[0:,house]\n",
    "ax1.plot(x, y_use_true, color='b',label='Actual energy')\n",
    "y_use_pred = [-1]*x_train[list(x_train.keys())[0]].shape[0]\n",
    "ax1.plot(x, y_use_pred, color='r', label='Predicted')\n",
    "ax1.set_ylim([0,7])\n",
    "ax1.set_ylabel('Whole Home')\n",
    "ax1.legend()\n",
    "\n",
    "#===========regrigerator============\n",
    "y_ref_true = np.asarray(x_test[list(x_test.keys())[0]])[0:,house]\n",
    "ax2.plot(x, y_ref_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_ref_pred = np.asarray(list(x_predict)[0])[0:,house]\n",
    "ax2.plot(x, y_ref_pred, color='r')\n",
    "#ax2.get_yaxis().set_visible(False)\n",
    "ax2.set_ylabel('Refrigerator')\n",
    "ax2.set_ylim([0,0.05])\n",
    "\n",
    "\n",
    "#===========dishwasher============\n",
    "y_dish_true = np.asarray(x_test[list(x_test.keys())[1]])[0:,house]\n",
    "ax3.plot(x, y_dish_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_dish_pred = np.asarray(list(x_predict)[1])[0:,house]\n",
    "ax3.plot(x,y_dish_pred, color='r')\n",
    "#ax3.get_yaxis().set_visible(False)\n",
    "ax3.set_ylabel('Dishwasher')\n",
    "#ax3.set_ylim(-0.00001)\n",
    "\n",
    "#===========furnace============\n",
    "y_fur_true = np.asarray(x_test[list(x_test.keys())[2]])[0:,house]\n",
    "ax4.plot(x, y_fur_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_fur_pred = np.asarray(list(x_predict)[2])[0:,house]\n",
    "ax4.plot(x,y_fur_pred, color='r')\n",
    "#ax4.get_yaxis().set_visible(False)\n",
    "ax4.set_ylabel('Furnace')\n",
    "# ax4.set_ylim(-0.05, 0.05)\n",
    "\n",
    "#===========Air============\n",
    "y_air_true = np.asarray(x_test[list(x_test.keys())[3]])[0:,house]\n",
    "ax5.plot(x, y_air_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_air_pred = np.asarray(list(x_predict)[3])[0:,house]\n",
    "ax5.plot(x, y_air_pred, color='r')\n",
    "#ax5.get_yaxis().set_visible(False)\n",
    "ax5.set_ylabel('Air')\n",
    "# ax5.set_xlabel('Hours')\n",
    "\n",
    "#===========others============\n",
    "y_other_true = np.asarray(x_test[list(x_test.keys())[4]])[0:,house]\n",
    "ax6.plot(x, y_other_true, color='b')\n",
    "x_predict = sc.predict(A_list,B_list)\n",
    "y_other_pred = np.asarray(list(x_predict)[4])[0:,house]\n",
    "ax6.plot(x, y_other_pred, color='r')\n",
    "#ax5.get_yaxis().set_visible(False)\n",
    "ax6.set_ylabel('Others')\n",
    "ax6.set_xlabel('Hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart_true = [y_ref_true.sum(), y_dish_true.sum(), y_fur_true.sum(), y_air_true.sum(), y_other_true.sum()]\n",
    "pie_chart_pred = [y_ref_pred.sum(), y_dish_pred.sum(), y_fur_pred.sum(), y_air_pred.sum(), y_other_pred.sum()]\n",
    "\n",
    "plt.style.use('classic')\n",
    "\n",
    "def pie_chart(subplot, pie_chart, labels):\n",
    "    # The slices will be ordered and plotted counter-clockwise.\n",
    "    ## --- Plotting the true-piechart\n",
    "    pie_chart_sum = sum(pie_chart)\n",
    "    pie_chart = list(map(lambda x: x/pie_chart_sum,pie_chart))\n",
    "    cmap = plt.cm.prism\n",
    "    colors = cmap(np.linspace(0., 1., len(pie_chart)))\n",
    "    pie_wedge_collection = subplot.pie(pie_chart, colors=colors, labels=labels, labeldistance=1.03)\n",
    "\n",
    "    for pie_wedge in pie_wedge_collection[0]:\n",
    "        pie_wedge.set_edgecolor('white')\n",
    "    # Set aspect ratio to be equal so that pie is drawn as a circle.\n",
    "    \n",
    "    \n",
    "f, ((axes1, axes2)) = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(16,16))\n",
    "\n",
    "labels = x_test.keys()\n",
    "print(labels)\n",
    "pie_chart(axes1,pie_chart_true,labels)\n",
    "axes1.set_title('True usage')\n",
    "pie_chart(axes2,pie_chart_pred,labels)\n",
    "axes2.set_title('Predicted usage')\n",
    "# axes2.text(0.95, 0.01, 'Accuracy of ' + str(round(sc.acc[0],1)), verticalalignment='center', horizontalalignment='right', transform=axes2.transAxes, color='black', fontsize=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the B matrices (basis functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "# row and column sharing\n",
    "f, ((ax1, ax2, ax3)) = plt.subplots(3, 1, sharex='col', sharey='row', figsize=(16,12))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "B_list[0] = B_list[0]/np.sum(B_list[0],axis=1)[:,None]  # Normalize\n",
    "ax1.pcolor(B_list[0], cmap = cm.Greys_r)\n",
    "B_list[1] = B_list[1]/np.sum(B_list[1],axis=1)[:,None]  # Normalize\n",
    "ax2.pcolor(B_list[1], cmap = cm.Greys_r)\n",
    "B_list[2] = B_list[2]/np.sum(B_list[2],axis=1)[:,None]  # Normalize\n",
    "ax3.pcolor(B_list[2], cmap = cm.Greys_r)\n",
    "\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax2.get_xaxis().set_visible(False)\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "ax3.get_xaxis().set_visible(False)\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "\n",
    "# plt.savefig(figure_directory+'basis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "\n",
    "# row and column sharing\n",
    "f, ((ax1, ax2, ax3)) = plt.subplots(3, 1, sharex='col', sharey='row', figsize=(16,12))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "for base in range(7):\n",
    "    ax1.plot(range(n),B_list[0][base,0:])\n",
    "    ax2.plot(range(n),B_list[1][base,0:])\n",
    "    ax3.plot(range(n),B_list[2][base,0:])\n",
    "\n",
    "ax1.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "ax1.set_ylim([0,0.04])\n",
    "ax1.set_ylabel('Refrigerator')\n",
    "ax2.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "ax2.set_ylim([0,0.06])\n",
    "ax2.set_ylabel('Dishwasher')\n",
    "ax3.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "ax3.set_ylim([0,0.02])\n",
    "ax3.set_ylabel('Furnace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
